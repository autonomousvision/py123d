{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4df83e45",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pyarrow as pa\n",
        "from pathlib import Path\n",
        "\n",
        "import gzip\n",
        "import json\n",
        "from typing import Dict\n",
        "import numpy as np\n",
        "\n",
        "from asim.dataset.dataset_specific.carla.data_conversion import CarlaDataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52772fce",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "dataset = CarlaDataset(Path(\"/home/daniel/asim_workspace/data\"))\n",
        "log_names = [path.name for path in dataset._log_path.iterdir()]\n",
        "\n",
        "for log_name in log_names:\n",
        "    print(f\"Converting log: {log_name}...\")\n",
        "    dataset.convert(log_name)\n",
        "    print(f\"Converting log: {log_name}...DONE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64f8c3b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# def _load_json_gz(path: Path) -> Dict:\n",
        "#     with gzip.open(path, \"rt\") as f:\n",
        "#         data = json.load(f)\n",
        "\n",
        "#     return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbacbdbe",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from curses import meta\n",
        "# from typing import List\n",
        "\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# from asim.common.geometry.bounding_box.bounding_box import BoundingBoxSE3Index\n",
        "# from asim.common.vehicle_state.ego_vehicle_state import EgoVehicleStateIndex\n",
        "# from asim.dataset.arrow.multiple_table import save_arrow_tables\n",
        "\n",
        "\n",
        "# def get_metadata_table(location: str) -> pa.Table:\n",
        "#     import asim\n",
        "\n",
        "#     metadata = {\n",
        "#         \"dataset\": \"carla\",\n",
        "#         \"location\": location,\n",
        "#         \"vehicle_name\": \"carla\",\n",
        "#         \"version\": str(asim.__version__),\n",
        "#     }\n",
        "#     metadata_fields = []\n",
        "#     metadata_values = []\n",
        "#     for key, value in metadata.items():\n",
        "#         metadata_fields.append(key)\n",
        "#         metadata_values.append(pa.scalar(value))\n",
        "\n",
        "#     return pa.Table.from_arrays([pa.array([value]) for value in metadata_values], metadata_fields)\n",
        "\n",
        "\n",
        "# def boxes_path_to_arrow(boxes_path: Path, arrow_path: Path) -> None:\n",
        "#     sorted_paths = sorted([bb_path for bb_path in boxes_path.iterdir()])\n",
        "\n",
        "#     timestamp_log: List[int] = []\n",
        "\n",
        "#     detections_state_log: List[List[List[float]]] = []\n",
        "#     detections_token_log: List[List[str]] = []\n",
        "#     detections_type_log: List[List[int]] = []\n",
        "\n",
        "#     ego_states_log: List[List[float]] = []\n",
        "\n",
        "#     traffic_light_ids_log: List[List[int]] = []\n",
        "#     traffic_light_types_log: List[List[int]] = []\n",
        "#     scenario_tags_log: List[List[str]] = []\n",
        "\n",
        "#     for box_path in tqdm(sorted_paths):\n",
        "#         # if box_path.suffix == \".json.gz\":\n",
        "#         data = _load_json_gz(box_path)\n",
        "#         timestamp_log.append(data[\"timestamp\"])\n",
        "#         detections_state_log.append(data[\"detections_state\"])\n",
        "#         detections_token_log.append(data[\"detections_token\"])\n",
        "#         detections_type_log.append(data[\"detections_types\"])\n",
        "#         ego_states_log.append(data[\"ego_state\"])\n",
        "#         traffic_light_ids_log.append(data[\"traffic_light_ids\"])\n",
        "#         traffic_light_types_log.append(data[\"traffic_light_types\"])\n",
        "#         scenario_tags_log.append(data[\"scenario_tag\"])\n",
        "\n",
        "#     recording_data = {\n",
        "#         \"timestamp\": timestamp_log,\n",
        "#         \"detections_state\": detections_state_log,\n",
        "#         \"detections_token\": detections_token_log,\n",
        "#         \"detections_type\": detections_type_log,\n",
        "#         \"ego_states\": ego_states_log,\n",
        "#         \"traffic_light_ids\": traffic_light_ids_log,\n",
        "#         \"traffic_light_types\": traffic_light_types_log,\n",
        "#         \"scenario_tag\": scenario_tags_log,\n",
        "#     }\n",
        "\n",
        "#     # Create a PyArrow Table\n",
        "#     recording_schema = pa.schema(\n",
        "#         [\n",
        "#             (\"timestamp\", pa.int64()),\n",
        "#             (\"detections_state\", pa.list_(pa.list_(pa.float64(), len(BoundingBoxSE3Index)))),\n",
        "#             (\"detections_token\", pa.list_(pa.string())),\n",
        "#             (\"detections_type\", pa.list_(pa.int16())),\n",
        "#             (\"ego_states\", pa.list_(pa.float64(), len(EgoVehicleStateIndex))),\n",
        "#             (\"traffic_light_ids\", pa.list_(pa.int64())),\n",
        "#             (\"traffic_light_types\", pa.list_(pa.int16())),\n",
        "#             (\"scenario_tag\", pa.list_(pa.string())),\n",
        "#         ]\n",
        "#     )\n",
        "#     recording_table = pa.Table.from_pydict(recording_data, schema=recording_schema)\n",
        "#     recording_table = recording_table.sort_by(\"timestamp\")\n",
        "\n",
        "#     tables: Dict[str, pa.Table] = {}\n",
        "#     tables[\"recording_table\"] = pa.Table.from_pydict(recording_data, schema=recording_schema)\n",
        "#     tables[\"metadata_table\"] = get_metadata_table(_load_json_gz(box_path)[\"location\"])\n",
        "\n",
        "#     # multi_table = ArrowMultiTableFile(self._output_path / self._split / f\"{log_name}.arrow\")\n",
        "#     log_file_path = arrow_path / \"carla\" / f\"{boxes_path.parent.name}.arrow\"\n",
        "#     if not log_file_path.parent.exists():\n",
        "#         log_file_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "#     save_arrow_tables(tables, log_file_path)\n",
        "\n",
        "\n",
        "# arrow_path = Path(\"/home/daniel/asim_workspace/data\")\n",
        "# data_path = Path(\"/home/daniel/carla_workspace/data/\")\n",
        "\n",
        "# for log_path in data_path.iterdir():\n",
        "\n",
        "#     boxes_path = log_path / \"boxes\"\n",
        "#     if not boxes_path.exists():\n",
        "#         print(f\"Boxes path {boxes_path} does not exist, skipping.\")\n",
        "#         continue\n",
        "#     print(f\"Processing {boxes_path}...\")\n",
        "#     boxes_path_to_arrow(boxes_path, arrow_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "302ac239",
      "metadata": {},
      "outputs": [],
      "source": [
        "step_tmp = 1000\n",
        "\n",
        "print(f\"{step_tmp:010d}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f87f8f4a",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "asim",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
