{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split = \"test\"\n",
    "\n",
    "\n",
    "split = \"train\"\n",
    "# split = \"val\"\n",
    "\n",
    "split_folder = Path(f\"/media/nvme1/argoverse/sensor_mini/{split}\")\n",
    "log_folder = sorted(list(split_folder.iterdir()))[0]\n",
    "\n",
    "log_folder.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ls(path: Path):\n",
    "    \"\"\"List all files in the given path.\"\"\"\n",
    "    return [f.name for f in path.iterdir()]\n",
    "\n",
    "\n",
    "def get_arrow_from_file(file_path: Path):\n",
    "    if file_path.suffix == \".parquet\":\n",
    "        import pyarrow.parquet as pq\n",
    "        return pq.read_table(file_path)\n",
    "    elif file_path.suffix == \".feather\":\n",
    "        import pyarrow.feather as feather\n",
    "        return feather.read_feather(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {file_path.suffix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 1. Calibration \n",
    "calibration_folder = log_folder / \"calibration\"\n",
    "\n",
    "# 1.1 -> ego to sensor transformation\n",
    "egovehicle_SE3_sensor_file = log_folder / \"calibration\" / \"egovehicle_SE3_sensor.feather\"\n",
    "egovehicle_se3_sensor_table = get_arrow_from_file(egovehicle_SE3_sensor_file)\n",
    "\n",
    "egovehicle_se3_sensor_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 -> intrinsic parameters\n",
    "intrinsics_file = log_folder / \"calibration\" / \"intrinsics.feather\"\n",
    "intrinsics_table = get_arrow_from_file(intrinsics_file)\n",
    "\n",
    "\n",
    "intrinsics_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Ego Vehicle\n",
    "city_SE3_egovehicle_file = log_folder / \"city_SE3_egovehicle.feather\"\n",
    "city_se3_egovehicle_table = get_arrow_from_file(city_SE3_egovehicle_file)\n",
    "\n",
    "city_se3_egovehicle_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 3. Map\n",
    "# # map_folder = log_folder / \"map\"\n",
    "# # print(_ls(map_folder))\n",
    "\n",
    "# # # 4. sensors\n",
    "# # print(_ls(log_folder))\n",
    "\n",
    "# # from d123.datasets.av2.av2_data_converter import AV2SensorDataConverter\n",
    "# from d123.datasets.av2.av2_data_converter import AV2SensorDataConverter\n",
    "\n",
    "# # AV2SensorDataConverter([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Annotations\n",
    "annotations_file = log_folder / \"annotations.feather\"\n",
    "annotations_table = get_arrow_from_file(annotations_file)\n",
    "\n",
    "# print(_ls(annotations_folder))\n",
    "annotations_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_name = \"ring_side_left\"\n",
    "\n",
    "camera_folder = log_folder / \"sensors\" / \"cameras\" / camera_name\n",
    "camera_files = sorted(list(camera_folder.iterdir()))\n",
    "\n",
    "\n",
    "def jpg_to_array(file_path):\n",
    "    image = np.array(Image.open(io.BytesIO(file_path.read_bytes())))\n",
    "    return image\n",
    "\n",
    "plt.imshow(jpg_to_array(camera_files[1]))\n",
    "print(len(camera_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lidar_folder = log_folder / \"sensors\" / \"lidar\" \n",
    "lidar_files = sorted(list(lidar_folder.iterdir()))\n",
    "\n",
    "\n",
    "get_arrow_from_file(lidar_files[0])\n",
    "\n",
    "print(lidar_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing sensor syn dataframes\n",
    "\n",
    "from typing import Optional\n",
    "from d123.datasets.av2.av2_constants import AV2_CAMERA_TYPE_MAPPING\n",
    "from d123.datasets.av2.av2_helper import build_sensor_dataframe, build_synchronization_dataframe\n",
    "\n",
    "\n",
    "sensor_df = build_sensor_dataframe(log_folder)\n",
    "synchronization_df = build_synchronization_dataframe(sensor_df)\n",
    "dataset_dir = split_folder.parent\n",
    "\n",
    "\n",
    "def find_closest_target_fpath(\n",
    "    split: str,\n",
    "    log_id: str,\n",
    "    src_sensor_name: str,\n",
    "    src_timestamp_ns: int,\n",
    "    target_sensor_name: str,\n",
    ") -> Optional[Path]:\n",
    "    \"\"\"Find the file path to the target sensor from a source sensor.\"\"\"\n",
    "    if synchronization_df is None:\n",
    "        raise RuntimeError(\"Requested synchronized data, but the synchronization database has not been created.\")\n",
    "\n",
    "    src_timedelta_ns = pd.Timedelta(src_timestamp_ns)\n",
    "    src_to_target_records = synchronization_df.loc[(split, log_id, src_sensor_name)].set_index(src_sensor_name)\n",
    "    index = src_to_target_records.index\n",
    "    if src_timedelta_ns not in index:\n",
    "        # This timestamp does not correspond to any lidar sweep.\n",
    "        return None\n",
    "\n",
    "    # Grab the synchronization record.\n",
    "    target_timestamp_ns = src_to_target_records.loc[src_timedelta_ns, target_sensor_name]\n",
    "    if pd.isna(target_timestamp_ns):\n",
    "        # No match was found within tolerance.\n",
    "        return None\n",
    "\n",
    "    sensor_dir = dataset_dir / split / log_id / \"sensors\"\n",
    "    valid_cameras = list(AV2_CAMERA_TYPE_MAPPING.keys())\n",
    "    timestamp_ns_str = str(target_timestamp_ns.asm8.item())\n",
    "    if target_sensor_name in valid_cameras:\n",
    "        target_path = sensor_dir / \"cameras\" / target_sensor_name / f\"{timestamp_ns_str}.jpg\"\n",
    "    else:\n",
    "        target_path = sensor_dir / target_sensor_name / f\"{timestamp_ns_str}.feather\"\n",
    "    return target_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split=\"train\"\n",
    "# log_id=\"00a6ffc1-6ce9-3bc3-a060-6006e9893a1a\"\n",
    "# src_sensor_name=\"ring_front_center\"\n",
    "# src_timestamp_ns=315967376959702000\n",
    "# target_sensor_name=\"lidar\"\n",
    "\n",
    "# src_to_target_records = synchronization_df.loc[(\"train\", \"\", src_sensor_name)]\n",
    "# # synchronization_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_timestamp_ns_list = [int(path.stem) for path in lidar_files]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for lidar_timestamp_ns in lidar_timestamp_ns_list:\n",
    "\n",
    "    fpath = find_closest_target_fpath(\n",
    "        split=\"train\",\n",
    "        log_id=log_folder.name,\n",
    "        src_sensor_name=\"lidar\",\n",
    "        src_timestamp_ns=lidar_timestamp_ns,\n",
    "        target_sensor_name=\"ring_front_center\",\n",
    "    )\n",
    "    if fpath is None:\n",
    "        continue\n",
    "    # print(fpath)\n",
    "\n",
    "    egovehicle_se3_sensor_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in egovehicle_se3_sensor_table.iterrows():\n",
    "    row = row.to_dict()\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pyquaternion import Quaternion\n",
    "\n",
    "lidar_timestamps = [int(f.stem) for f in lidar_files]\n",
    "camera_timestamps = [int(f.stem) for f in camera_files]\n",
    "\n",
    "\n",
    "def get_slice_with_timestamp_ns(dataframe: pd.DataFrame, timestamp_ns: int):\n",
    "    \"\"\"Get the index of the closest timestamp to the target timestamp.\"\"\"\n",
    "    return dataframe[dataframe[\"timestamp_ns\"] == timestamp_ns]\n",
    "\n",
    "\n",
    "def find_nearest_timestamp(target_ns, timestamp_list):\n",
    "    timestamp_array = np.array(timestamp_list, dtype=np.int64)\n",
    "    idx = np.argmin(np.abs(timestamp_array - np.int64(target_ns)))\n",
    "    return int(timestamp_array[idx])\n",
    "\n",
    "# for lidar_timestamp in lidar_timestamps:\n",
    "#     slice = get_slice_with_timestamp_ns(annotations_table, lidar_timestamp)\n",
    "#     assert len(slice) >= 1\n",
    "\n",
    "\n",
    "\n",
    "# ego_pose = city_SE3_egovehicle_table[city_SE3_egovehicle_table[\"timestamp_ns\"] == lidar_timestamps[10]]\n",
    "# ego_pose_dict = ego_pose.iloc[0].to_dict()\n",
    "\n",
    "\n",
    "annotations_slice = get_slice_with_timestamp_ns(annotations_table, lidar_timestamps[10])\n",
    "for _, row in annotations_slice.iterrows():\n",
    "#     qw = row[\"qw\"]\n",
    "#     qx = row[\"qx\"]\n",
    "#     qy = row[\"qy\"]\n",
    "#     qz = row[\"qz\"]\n",
    "#     tx_m = row[\"tx_m\"]\n",
    "#     ty_m = row[\"ty_m\"]\n",
    "#     tz_m = row[\"tz_m\"]\n",
    "    print(row.to_dict())\n",
    "\n",
    "annotations_slice\n",
    "\n",
    "# qw\tqx\tqy\tqz\ttx_m\tty_m\ttz_m\n",
    "# # def jpg_to_array(file_path):\n",
    "\n",
    "# camera_frames = []\n",
    "# for lidar_timestamp in lidar_timestamps:\n",
    "#     camera_stamp_at_lidar = find_nearest_timestamp(lidar_timestamp, camera_timestamps)\n",
    "#     image = jpg_to_array(camera_folder / f\"{camera_stamp_at_lidar}.jpg\")\n",
    "#     camera_frames.append(image)\n",
    "    \n",
    "# print(len(camera_frames))\n",
    "# height, width, _ = camera_frames[0].shape\n",
    "# video_path = \"camera_frames_video.mp4\"\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# out = cv2.VideoWriter(video_path, fourcc, 10, (width, height))\n",
    "\n",
    "# for frame in camera_frames:\n",
    "#     out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# out.release()\n",
    "# print(f\"Saved video to {video_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pyquaternion import Quaternion\n",
    "d123.datatypes.detections.detection_types import DetectionType\n",
    "from d123.geometry.base import StateSE2\n",
    "from d123.geometry.bounding_box import BoundingBoxSE2\n",
    "from d123.common.visualization.color.config import PlotConfig\n",
    "from d123.common.visualization.color.default import BOX_DETECTION_CONFIG\n",
    "from d123.common.visualization.matplotlib.utils import add_shapely_polygon_to_ax\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "for cuboid in sensor_data.annotations:\n",
    "    yaw, pitch, roll = Quaternion(matrix=cuboid.dst_SE3_object.rotation).yaw_pitch_roll\n",
    "    center = StateSE2(cuboid.dst_SE3_object.translation[0], cuboid.dst_SE3_object.translation[1], yaw)\n",
    "    bounding_box = BoundingBoxSE2(center, cuboid.length_m, cuboid.width_m)\n",
    "    add_shapely_polygon_to_ax(ax, bounding_box.shapely_polygon, BOX_DETECTION_CONFIG[DetectionType.VEHICLE])\n",
    "\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "radius = 200\n",
    "ax.set_xlim(-radius, radius)\n",
    "ax.set_ylim(-radius, radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_box.shapely_polygon\n",
    "\n",
    "bounding_box.corners_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sensor_cache = \"/home/daniel/.cache/av2/sensor_cache.feather\"\n",
    "get_arrow_from_file(Path(sensor_cache))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "synchronization_cache = \"/home/daniel/.cache/av2/synchronization_cache.feather\"\n",
    "synchronization_cache = get_arrow_from_file(Path(synchronization_cache))\n",
    "\n",
    "synchronization_cache[\"sensor_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAM_SHUTTER_INTERVAL_MS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d123",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
