{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_uri = \"asimtesting/nuplan_private_test/2021.07.25.16.16.23_veh-26_02446_02589.arrow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.fs as fs\n",
    "import pyarrow.dataset as ds\n",
    "\n",
    "import os\n",
    "\n",
    "s3_fs = fs.S3FileSystem(\n",
    "    access_key=os.environ.get('AWS_ACCESS_KEY_ID'),\n",
    "    secret_key=os.environ.get('AWS_SECRET_ACCESS_KEY'),\n",
    "    region=os.environ.get('AWS_DEFAULT_REGION')\n",
    ")\n",
    "from asim.common.utils.timer import Timer\n",
    "\n",
    "\n",
    "timer = Timer()\n",
    "timer.start()\n",
    "\n",
    "dataset = ds.dataset(f\"{s3_uri}\", format=\"ipc\", filesystem=s3_fs)\n",
    "timer.log(\"1. Dataset loaded\")\n",
    "\n",
    "# Get all column names and remove the ones you want to drop\n",
    "all_columns = dataset.schema.names\n",
    "columns_to_keep = [col for col in all_columns if col not in [\"front_cam_demo\", \"front_cam_transform\"]]\n",
    "timer.log(\"2. Columns filtered\")\n",
    "\n",
    "table = dataset.to_table(columns=columns_to_keep)\n",
    "timer.log(\"3. Table created\")\n",
    "# Save locally\n",
    "with pa.ipc.new_file(\"filtered_file.arrow\", table.schema) as writer:\n",
    "    writer.write_table(table)\n",
    "timer.log(\"4. Table saved locally\")\n",
    "\n",
    "timer.end()\n",
    "timer.stats(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = Timer()\n",
    "timer.start()\n",
    "\n",
    "table = dataset.take([i for i in range(0, 100, 1)], columns=all_columns)\n",
    "timer.log(\"3. Table created\")\n",
    "\n",
    "# Save locally\n",
    "with pa.ipc.new_file(\"filtered_file_v2.arrow\", table.schema) as writer:\n",
    "    writer.write_table(table)\n",
    "\n",
    "timer.log(\"4. Table saved locally\")\n",
    "timer.end()\n",
    "timer.stats(verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pa.memory_map(\"filtered_file_v2.arrow\", \"r\") as source:\n",
    "#     mmap_table = pa.ipc.open_file(source).read_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyarrow.parquet as pq\n",
    "# import pyarrow.dataset as ds\n",
    "# import pyarrow.dataset as ds\n",
    "# import pyarrow as pa\n",
    "# from huggingface_hub import hf_hub_download\n",
    "# from io import BytesIO\n",
    "\n",
    "# # Download specific file from the repo\n",
    "# file_path = hf_hub_download(\n",
    "#     repo_id=\"DanielDauner/delete_me\",\n",
    "#     filename=\"2021.05.25.14.16.10_veh-35_01690_02183.arrow\",  # or whatever the file is named\n",
    "#     repo_type=\"dataset\"\n",
    "# )\n",
    "\n",
    "# # Read with PyArrow\n",
    "# with pa.memory_map(file_path, \"r\") as source:\n",
    "#     mmap_table = pa.ipc.open_file(source).read_all()\n",
    "\n",
    "# # Create dataset and slice\n",
    "# sliced_table = mmap_table.slice(0, 1000)  # First 1000 rows\n",
    "# sliced_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
