{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from shapely.geometry import LineString, Polygon, Point\n",
        "import numpy as np\n",
        "\n",
        "from typing import List\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from nuplan.database.nuplan_db_orm.nuplandb import LidarBox\n",
        "\n",
        "import pyarrow as pa\n",
        "import pyarrow.ipc as ipc\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from asim.common.geometry.base import StateSE3\n",
        "from asim.common.geometry.bounding_box.bounding_box import BoundingBoxSE3\n",
        "from asim.common.geometry.constants import DEFAULT_ROLL, DEFAULT_PITCH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from asim.dataset.maps.abstract_map import MapSurfaceType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nuplan.database.nuplan_db_orm.nuplandb import NuPlanDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from asim.dataset.dataset_specific.nuplan.data_conversion import NuPlanDataset\n",
        "\n",
        "\n",
        "NUPLAN_DATA_ROOT = Path(os.environ[\"NUPLAN_DATA_ROOT\"])\n",
        "SPLIT_PATH = NUPLAN_DATA_ROOT / \"nuplan-v1.1\" / \"splits\" / \"mini\"\n",
        "\n",
        "\n",
        "db_files = list(SPLIT_PATH.iterdir())\n",
        "# idx = 0\n",
        "# for idx in range(len(db_files)):\n",
        "idx = 14\n",
        "\n",
        "log_db = NuPlanDB(NUPLAN_DATA_ROOT, str(db_files[idx]), None)\n",
        "print(idx, log_db.log_name, log_db.log.map_version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from asim.dataset.observation.agent_datatypes import BoundingBoxType\n",
        "\n",
        "\n",
        "name_mapping = {\n",
        "    \"vehicle\": BoundingBoxType.VEHICLE,\n",
        "    \"bicycle\": BoundingBoxType.BICYCLE,\n",
        "    \"pedestrian\": BoundingBoxType.PEDESTRIAN,\n",
        "    \"traffic_cone\": BoundingBoxType.TRAFFIC_CONE,\n",
        "    \"barrier\": BoundingBoxType.BARRIER,\n",
        "    \"czone_sign\": BoundingBoxType.CZONE_SIGN,\n",
        "    \"generic_object\": BoundingBoxType.GENERIC_OBJECT,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nuplan.common.geometry.compute import get_pacifica_parameters\n",
        "\n",
        "\n",
        "log_name = log_db.log_name\n",
        "log_token = log_db.log.token\n",
        "map_location = log_db.log.map_version\n",
        "vehicle_name = log_db.log.vehicle_name\n",
        "\n",
        "\n",
        "time_us_log: List[int] = []\n",
        "\n",
        "bb_ego_log: List[List[float]] = []\n",
        "bb_frame_log: List[List[List[float]]] = []\n",
        "bb_track_log: List[List[str]] = []\n",
        "bb_types_log: List[List[int]] = []\n",
        "\n",
        "ego_states_log: List[List[float]] = []\n",
        "\n",
        "\n",
        "for lidar_pc in tqdm(log_db.lidar_pc, dynamic_ncols=True):\n",
        "    # 1. time_us\n",
        "    time_us_log.append(lidar_pc.timestamp)\n",
        "\n",
        "    bb_frame: List[List[float]] = []\n",
        "    bb_track: List[str] = []\n",
        "    bb_types: List[int] = []\n",
        "\n",
        "    for lidar_box in lidar_pc.lidar_boxes:\n",
        "        lidar_box: LidarBox\n",
        "        center = StateSE3(\n",
        "            x=lidar_box.x,\n",
        "            y=lidar_box.y,\n",
        "            z=lidar_box.z,\n",
        "            roll=DEFAULT_ROLL,\n",
        "            pitch=DEFAULT_PITCH,\n",
        "            yaw=lidar_box.yaw,\n",
        "        )\n",
        "        bounding_box_se3 = BoundingBoxSE3(center, lidar_box.length, lidar_box.width, lidar_box.height)\n",
        "\n",
        "        bb_frame.append(pa.array(bounding_box_se3.array))\n",
        "        bb_track.append(lidar_box.track_token)\n",
        "        bb_types.append(int(name_mapping[lidar_box.category.name]))\n",
        "\n",
        "    bb_frame_log.append(bb_frame)\n",
        "    bb_track_log.append(bb_track)\n",
        "    bb_types_log.append(bb_types)\n",
        "\n",
        "    # 2. ego_states\n",
        "    yaw, pitch, roll = yaw_pitch_roll = lidar_pc.ego_pose.quaternion.yaw_pitch_roll\n",
        "    vehicle_parameters = get_pacifica_parameters()\n",
        "    ego_bounding_box_se3 = BoundingBoxSE3(\n",
        "        center=StateSE3(\n",
        "            x=lidar_pc.ego_pose.x,\n",
        "            y=lidar_pc.ego_pose.y,\n",
        "            z=lidar_pc.ego_pose.z,\n",
        "            roll=roll,\n",
        "            pitch=pitch,\n",
        "            yaw=yaw,\n",
        "        ),\n",
        "        length=vehicle_parameters.length,\n",
        "        width=vehicle_parameters.width,\n",
        "        height=vehicle_parameters.height,\n",
        "    )\n",
        "\n",
        "    bb_ego_log.append(pa.array(ego_bounding_box_se3.array))\n",
        "\n",
        "    if len(bb_ego_log) > 9:\n",
        "        break\n",
        "    # break\n",
        "\n",
        "\n",
        "# Option 1: List Column Approach\n",
        "list_data = {\"time_us\": time_us_log, \"bb_frame\": bb_frame_log, \"bb_track\": bb_track_log, \"bb_types\": bb_types_log, \"bb_ego\": bb_ego_log}\n",
        "\n",
        "# Create a PyArrow Table\n",
        "list_schema = pa.schema(\n",
        "    [\n",
        "        (\"time_us\", pa.int64()),\n",
        "        (\"bb_frame\", pa.list_(pa.list_(pa.float64(), 9))),\n",
        "        (\"bb_track\", pa.list_(pa.string())),\n",
        "        (\"bb_types\", pa.list_(pa.int32())),\n",
        "        (\"bb_ego\", pa.list_(pa.float64(), 9)),\n",
        "    ]\n",
        ")\n",
        "list_table = pa.Table.from_pydict(list_data, schema=list_schema)\n",
        "\n",
        "\n",
        "metadata = {\n",
        "    \"recording_id\": \"drive_20250515_001\",\n",
        "    \"location\": \"Mountain View, CA\",\n",
        "    \"weather\": \"sunny\",\n",
        "    \"sensor_config\": \"standard_suite_v3\"\n",
        "}\n",
        "metadata_fields = []\n",
        "metadata_values = []\n",
        "for key, value in metadata.items():\n",
        "    metadata_fields.append(key)\n",
        "    metadata_values.append(pa.scalar(value))\n",
        "\n",
        "metadata_table = pa.Table.from_arrays(\n",
        "    [pa.array([value]) for value in metadata_values],\n",
        "    metadata_fields\n",
        ")\n",
        "\n",
        "# schema = {\n",
        "#     \"timeseries\": list_table.schema,\n",
        "#     \"metadata\": metadata_table.schema\n",
        "# }\n",
        "# schema_batch = pa.record_batch([pa.array([str(schema)])], [\"schema\"])\n",
        "\n",
        "# # Write to Arrow file\n",
        "# # with pa.OSFile(f\"{log_name}.arrow\", \"wb\") as sink:\n",
        "# #     writer = pa.RecordBatchFileWriter(sink, list_table.schema)\n",
        "# #     writer.write_table(list_table)\n",
        "# #     writer.close()\n",
        "# schema_batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pyarrow as pa\n",
        "import pyarrow.ipc as ipc\n",
        "\n",
        "tables = [list_table, metadata_table]  # Different schemas\n",
        "\n",
        "with pa.OSFile(\"combined.arrow\", \"wb\") as sink:\n",
        "    writer = ipc.new_stream(sink, tables[0].schema)  # dummy schema, will be overwritten per chunk\n",
        "    for i, table in enumerate(tables):\n",
        "        metadata = {\"schema_index\": str(i)}\n",
        "        table = table.replace_schema_metadata(metadata)\n",
        "        writer.write_table(table)\n",
        "    writer.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "asim",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
