{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.ipc as ipc\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_to_arrow(input_folder, output_file, batch_size=100):\n",
    "    \"\"\"\n",
    "    Process JPEG images from a folder and save them as arrays in Arrow IPC format.\n",
    "\n",
    "    Args:\n",
    "        input_folder (str): Path to folder containing JPEG images\n",
    "        output_file (str): Path to output Arrow IPC file\n",
    "        batch_size (int): Number of images to process in each batch\n",
    "    \"\"\"\n",
    "\n",
    "    # Get all JPEG files in the folder\n",
    "    jpeg_extensions = [\"*.jpg\", \"*.jpeg\", \"*.JPG\", \"*.JPEG\"]\n",
    "    image_files = []\n",
    "\n",
    "    for ext in jpeg_extensions:\n",
    "        image_files.extend(glob.glob(os.path.join(input_folder, ext)))\n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"No JPEG files found in {input_folder}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(image_files)} JPEG files\")\n",
    "\n",
    "    # Create Arrow schema\n",
    "    schema = pa.schema(\n",
    "        [\n",
    "            # pa.field(\"filename\", pa.string()),\n",
    "            pa.field(\"image_array\", pa.binary()),\n",
    "            # pa.field(\"height\", pa.int32()),\n",
    "            # pa.field(\"width\", pa.int32()),\n",
    "            # pa.field(\"channels\", pa.int32()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Open Arrow IPC writer\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        writer = ipc.new_file(f, schema)\n",
    "\n",
    "        # Process images in batches\n",
    "        for i in range(0, len(image_files), batch_size):\n",
    "            batch_files = image_files[i : i + batch_size]\n",
    "\n",
    "            # Lists to store batch data\n",
    "            filenames = []\n",
    "            image_arrays = []\n",
    "            image_bytes = []\n",
    "            heights = []\n",
    "            widths = []\n",
    "            channels = []\n",
    "\n",
    "            print(f\"Processing batch {i//batch_size + 1}/{(len(image_files)-1)//batch_size + 1}\")\n",
    "\n",
    "            for img_path in batch_files:\n",
    "                try:\n",
    "                    # Load image\n",
    "                    # with Image.open(img_path) as img:\n",
    "                    #     # Convert to RGB if not already\n",
    "                    #     if img.mode != \"RGB\":\n",
    "                    #         img = img.convert(\"RGB\")\n",
    "                    with open(img_path, \"rb\") as f:\n",
    "                        jpg_bytes = f.read()\n",
    "\n",
    "                        # Convert to numpy array\n",
    "                        # img_array = np.array(img)\n",
    "\n",
    "                        # Store image data\n",
    "                        filenames.append(os.path.basename(img_path))\n",
    "                        image_bytes.append(jpg_bytes)\n",
    "                        # image_arrays.append(img_array.flatten().tolist())\n",
    "                        # heights.append(img_array.shape[0])\n",
    "                        # widths.append(img_array.shape[1])\n",
    "                        # channels.append(img_array.shape[2])\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {img_path}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            # Create Arrow arrays for this batch\n",
    "            if filenames:  # Only create batch if we have valid images\n",
    "                batch_data = pa.record_batch(\n",
    "                    [\n",
    "                        # pa.array(filenames),\n",
    "                        pa.array(image_bytes),\n",
    "                        # pa.array(heights),\n",
    "                        # pa.array(widths),\n",
    "                        # pa.array(channels),\n",
    "                    ],\n",
    "                    schema=schema,\n",
    "                )\n",
    "\n",
    "                # Write batch to file\n",
    "                writer.write_batch(batch_data)\n",
    "\n",
    "        writer.close()\n",
    "\n",
    "    print(f\"Successfully saved images to {output_file}\")\n",
    "\n",
    "\n",
    "def read_arrow_file(arrow_file):\n",
    "    \"\"\"\n",
    "    Read and display info about the Arrow IPC file.\n",
    "\n",
    "    Args:\n",
    "        arrow_file (str): Path to Arrow IPC file\n",
    "    \"\"\"\n",
    "    with open(arrow_file, \"rb\") as f:\n",
    "        reader = ipc.open_file(f)\n",
    "\n",
    "        print(f\"Schema: {reader.schema}\")\n",
    "        print(f\"Number of record batches: {reader.num_record_batches}\")\n",
    "\n",
    "        total_images = 0\n",
    "        for i in range(reader.num_record_batches):\n",
    "            batch = reader.get_batch(i)\n",
    "            total_images += len(batch)\n",
    "            print(f\"Batch {i}: {len(batch)} images\")\n",
    "\n",
    "        print(f\"Total images: {total_images}\")\n",
    "\n",
    "        # Show first few filenames as example\n",
    "        if reader.num_record_batches > 0:\n",
    "            first_batch = reader.get_batch(0)\n",
    "            print(f\"First few filenames: {first_batch['filename'][:5].to_pylist()}\")\n",
    "\n",
    "\n",
    "def reconstruct_image(arrow_file, filename, output_path):\n",
    "    \"\"\"\n",
    "    Reconstruct and save an image from the Arrow file.\n",
    "\n",
    "    Args:\n",
    "        arrow_file (str): Path to Arrow IPC file\n",
    "        filename (str): Name of the image file to reconstruct\n",
    "        output_path (str): Path to save reconstructed image\n",
    "    \"\"\"\n",
    "    with open(arrow_file, \"rb\") as f:\n",
    "        reader = ipc.open_file(f)\n",
    "\n",
    "        for i in range(reader.num_record_batches):\n",
    "            batch = reader.get_batch(i)\n",
    "\n",
    "            # Find the image by filename\n",
    "            filenames = batch[\"filename\"].to_pylist()\n",
    "            if filename in filenames:\n",
    "                idx = filenames.index(filename)\n",
    "\n",
    "                # Get image data\n",
    "                img_array = batch[\"image_array\"][idx].to_pylist()\n",
    "                height = batch[\"height\"][idx].as_py()\n",
    "                width = batch[\"width\"][idx].as_py()\n",
    "                channels = batch[\"channels\"][idx].as_py()\n",
    "\n",
    "                # Reconstruct image\n",
    "                img_array = np.array(img_array, dtype=np.uint8)\n",
    "                img_array = img_array.reshape(height, width, channels)\n",
    "\n",
    "                # Save image\n",
    "                img = Image.fromarray(img_array)\n",
    "                img.save(output_path)\n",
    "                print(f\"Image reconstructed and saved to {output_path}\")\n",
    "                return\n",
    "\n",
    "        print(f\"Image {filename} not found in Arrow file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_images_to_arrow(\"/mnt/nvme/nuplan/dataset/nuplan-v1.1/sensor/2021.07.01.20.35.47_veh-38_00016_00281/CAM_F0\", \"test.arrow\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read IPC file\n",
    "import io\n",
    "\n",
    "import time\n",
    "\n",
    "# with pa.OSFile(\"test.arrow\", 'rb') as source:\n",
    "#     with ipc.open_file(source) as reader:\n",
    "#         table = reader.read_all()\n",
    "\n",
    "with pa.ipc.open_file(\n",
    "    pa.memory_map(\"/home/daniel/asim_workspace/data/nuplan_private_test/2021.07.25.16.16.23_veh-26_02446_02589.arrow\")\n",
    ") as reader:\n",
    "    # This doesn't load data into memory yet!\n",
    "    table = reader.read_all()\n",
    "\n",
    "\n",
    "print(len(table))\n",
    "start = time.time()\n",
    "# Extract JPG data\n",
    "jpg_data = table[\"front_cam_demo\"][500].as_py()\n",
    "read_image = Image.open(io.BytesIO(jpg_data))\n",
    "\n",
    "# read_image = read_image.convert(\"RGB\")  # Ensure it's in RGB format\n",
    "read_image = np.array(read_image)\n",
    "print(read_image.dtype)\n",
    "print(f\"Image loaded in {time.time() - start:.4f} seconds\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(read_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuplan.database.nuplan_db_orm.nuplandb import NuPlanDB\n",
    "\n",
    "NUPLAN_DATA_ROOT = Path(os.environ[\"NUPLAN_DATA_ROOT\"])\n",
    "log_path = \"/mnt/nvme/nuplan/dataset/nuplan-v1.1/splits/private_test/2021.09.29.17.35.58_veh-44_01671_01819.db\"\n",
    "log_db = NuPlanDB(NUPLAN_DATA_ROOT, str(log_path), None)\n",
    "\n",
    "\n",
    "log_db.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from nuplan.database.nuplan_db.nuplan_scenario_queries import get_images_from_lidar_tokens, get_cameras\n",
    "from nuplan.planning.scenario_builder.nuplan_db.nuplan_scenario import NuPlanScenario, CameraChannel, LidarChannel\n",
    "from pyquaternion import Quaternion\n",
    "\n",
    "\n",
    "NUPLAN_DB_PATH = \"/mnt/nvme/nuplan/dataset/nuplan-v1.1/splits/private_test\"\n",
    "\n",
    "\n",
    "def get_log_cam_info(log):\n",
    "    log_name = log.logfile\n",
    "    log_file = os.path.join(NUPLAN_DB_PATH, log_name + \".db\")\n",
    "\n",
    "    log_cam_infos = {}\n",
    "    for cam in get_cameras(log_file, [str(CameraChannel.CAM_F0.value)]):\n",
    "        intrinsics = np.array(pickle.loads(cam.intrinsic))\n",
    "        translation = np.array(pickle.loads(cam.translation))\n",
    "        rotation = np.array(pickle.loads(cam.rotation))\n",
    "        print(rotation)\n",
    "        rotation = Quaternion(rotation).rotation_matrix\n",
    "        distortion = np.array(pickle.loads(cam.distortion))\n",
    "        c = dict(\n",
    "            intrinsic=intrinsics,\n",
    "            distortion=distortion,\n",
    "            translation=translation,\n",
    "            rotation=rotation,\n",
    "        )\n",
    "        log_cam_infos[cam.token] = c\n",
    "\n",
    "    return log_cam_infos\n",
    "\n",
    "\n",
    "images = []\n",
    "for lidar_pc in log_db.lidar_pc[::2]:\n",
    "\n",
    "    front_image = get_images_from_lidar_tokens(log_path, [lidar_pc.token], [str(CameraChannel.CAM_F0.value)])\n",
    "    parameters = get_log_cam_info(log_db.log)\n",
    "    print(parameters)\n",
    "\n",
    "    images.append(list(front_image))\n",
    "\n",
    "\n",
    "for image in images[0]:\n",
    "    print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters[\"0872b6c896e85f9f\"][\"rotation\"]\n",
    "\n",
    "\n",
    "# intrinsics = np.array([[1.545e03, 0.000e00, 9.600e02], [0.000e00, 1.545e03, 5.600e02], [0.000e00, 0.000e00, 1.000e00]])\n",
    "# distortion = np.array([-0.356123, 0.172545, -0.00213, 0.000464, -0.05231])\n",
    "# translation = np.array([ 1.66433035e+00, -1.32379618e-03,  1.57190200e+00])\n",
    "# rotation = np.array(\n",
    "#     [\n",
    "#         [-0.00395669, -0.03969443, 0.99920403],\n",
    "#         [-0.99971496, -0.02336898, -0.00488707],\n",
    "#         [0.02354437, -0.99893856, -0.03959065],\n",
    "#     ]\n",
    "# )\n",
    "# distortion\n",
    "\n",
    "np.array(\n",
    "    [\n",
    "        [-0.00395669, -0.03969443, 0.99920403],\n",
    "        [-0.99971496, -0.02336898, -0.00488707],\n",
    "        [0.02354437, -0.99893856, -0.03959065],\n",
    "    ]\n",
    ")\n",
    "np.array(\n",
    "    [\n",
    "        [-0.00395669, -0.03969443, 0.99920403],\n",
    "        [-0.99971496, -0.02336898, -0.00488707],\n",
    "        [0.02354437, -0.99893856, -0.03959065],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "for cam in get_cameras(log_path, [str(channel.value) for channel in CameraChannel]):\n",
    "    print(pickle.loads(cam.translation))\n",
    "    print(pickle.loads(cam.translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "9.600e02, 1920 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "sensor_root = Path(\"/mnt/nvme/nuplan/dataset/nuplan-v1.1/sensor\")\n",
    "\n",
    "frames = []\n",
    "for image in images:\n",
    "    if len(image) == 0:\n",
    "        continue\n",
    "\n",
    "    jpg_name = image[0].filename_jpg\n",
    "    jpg_path = sensor_root / jpg_name\n",
    "    with open(jpg_path, \"rb\") as f:\n",
    "        jpg_data = f.read()\n",
    "    read_image = Image.open(io.BytesIO(jpg_data))\n",
    "    read_image = np.array(read_image)\n",
    "    # Convert RGB to BGR for OpenCV\n",
    "    frame = cv2.cvtColor(read_image, cv2.COLOR_RGB2BGR)\n",
    "    frames.append(frame)\n",
    "\n",
    "# Define video writer\n",
    "height, width, _ = frames[0].shape\n",
    "out = cv2.VideoWriter(f\"{log_db.name}.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), 20, (width, height))\n",
    "\n",
    "for frame in frames:\n",
    "    out.write(frame)\n",
    "out.release()\n",
    "print(\"Video saved as output.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
