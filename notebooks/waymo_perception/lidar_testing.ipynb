{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from waymo_open_dataset import dataset_pb2\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from waymo_open_dataset import label_pb2\n",
    "from waymo_open_dataset.protos import camera_segmentation_pb2 as cs_pb2\n",
    "from waymo_open_dataset.utils import box_utils\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "WOPD_DATA_ROOT = Path(\"/media/nvme1/waymo_perception/training\")\n",
    "\n",
    "\n",
    "tfrecords_file_list = list(WOPD_DATA_ROOT.glob(\"*.tfrecord\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from pyquaternion import Quaternion\n",
    "\n",
    "from d123.geometry import StateSE3\n",
    "from d123.geometry.bounding_box import BoundingBoxSE3\n",
    "\n",
    "from waymo_open_dataset.utils import frame_utils\n",
    "\n",
    "\n",
    "# Frame attributes:\n",
    "#   context: <class 'waymo_open_dataset.dataset_pb2.Context'>\n",
    "#   timestamp_micros: <class 'int'>\n",
    "#   pose: <class 'waymo_open_dataset.dataset_pb2.Transform'>\n",
    "#   images: List with 5 images\n",
    "#   lasers: <class 'google._upb._message.RepeatedCompositeContainer'>\n",
    "#     Length: 5\n",
    "#   laser_labels: <class 'google._upb._message.RepeatedCompositeContainer'>\n",
    "#     Length: 0\n",
    "#   projected_lidar_labels: <class 'google._upb._message.RepeatedCompositeContainer'>\n",
    "#     Length: 0\n",
    "#   camera_labels: <class 'google._upb._message.RepeatedCompositeContainer'>\n",
    "#     Length: 0\n",
    "#   no_label_zones: <class 'google._upb._message.RepeatedCompositeContainer'>\n",
    "#     Length: 0\n",
    "#   map_features: <class 'google._upb._message.RepeatedCompositeContainer'>\n",
    "#     Length: 0\n",
    "#   map_pose_offset: <class 'waymo_open_dataset.protos.vector_pb2.Vector3d'>\n",
    "\n",
    "file_idx = 0\n",
    "pathname = tfrecords_file_list[file_idx]\n",
    "dataset = tf.data.TFRecordDataset(pathname, compression_type=\"\")\n",
    "num_frames = sum(1 for _ in dataset)\n",
    "\n",
    "\n",
    "def read_jpg_image(data: bytes) -> np.ndarray:\n",
    "    \"\"\"Read a JPEG image from bytes and return it as a numpy array.\"\"\"\n",
    "    image = Image.open(io.BytesIO(data))\n",
    "    return np.array(image)\n",
    "\n",
    "\n",
    "ego_state_se3s = []\n",
    "front_images = []\n",
    "dataset = tf.data.TFRecordDataset(pathname, compression_type=\"\")\n",
    "\n",
    "boxes = []\n",
    "\n",
    "for frame_idx, data in enumerate(dataset):\n",
    "\n",
    "    frame = dataset_pb2.Frame()\n",
    "    frame.ParseFromString(data.numpy())\n",
    "    # print(frame.camera_labels)\n",
    "    print(\"Frame attributes:\")\n",
    "    for field in frame.DESCRIPTOR.fields:\n",
    "        field_name = field.name\n",
    "        if hasattr(frame, field_name):\n",
    "            value = getattr(frame, field_name)\n",
    "            if field_name != \"images\":  # Don't print the whole image data\n",
    "                print(f\"  {field_name}: {type(value)}\")\n",
    "                if hasattr(value, \"__len__\") and not isinstance(value, (str, bytes)):\n",
    "                    print(f\"    Length: {len(value)}\")\n",
    "            else:\n",
    "                print(f\"  {field_name}: List with {len(value)} images\")\n",
    "\n",
    "\n",
    "    # # 1. pose\n",
    "    pose = np.array(frame.pose.transform).reshape(4, 4)\n",
    "    yaw_pitch_roll = Quaternion(matrix=pose[:3, :3]).yaw_pitch_roll\n",
    "    ego_state_se3s.append(\n",
    "        np.array(\n",
    "            [\n",
    "                pose[0, 3],  # x\n",
    "                pose[1, 3],  # y\n",
    "                pose[2, 3],  # z\n",
    "                yaw_pitch_roll[2],  # yaw\n",
    "                yaw_pitch_roll[1],  # pitch\n",
    "                yaw_pitch_roll[0],  # roll\n",
    "            ],\n",
    "            dtype=np.float64,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # # plt.show()\n",
    "    if frame_idx == 0:\n",
    "        break\n",
    "\n",
    "ego_state_se3s = np.array(ego_state_se3s, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from waymo_open_dataset import dataset_pb2\n",
    "from waymo_open_dataset.utils import range_image_utils\n",
    "from waymo_open_dataset.utils import transform_utils\n",
    "\n",
    "RangeImages = Dict[\"dataset_pb2.LaserName.Name\", List[dataset_pb2.MatrixFloat]]\n",
    "CameraProjections = Dict[\"dataset_pb2.LaserName.Name\", List[dataset_pb2.MatrixInt32]]\n",
    "SegmentationLabels = Dict[\"dataset_pb2.LaserName.Name\", List[dataset_pb2.MatrixInt32]]\n",
    "ParsedFrame = Tuple[RangeImages, CameraProjections, SegmentationLabels, dataset_pb2.MatrixFloat]\n",
    "\n",
    "\n",
    "def parse_range_image_and_camera_projection(frame: dataset_pb2.Frame) -> ParsedFrame:\n",
    "    \"\"\"Parse range images and camera projections given a frame.\n",
    "\n",
    "    Args:\n",
    "      frame: open dataset frame proto\n",
    "\n",
    "    Returns:\n",
    "      range_images: A dict of {laser_name,\n",
    "        [range_image_first_return, range_image_second_return]}.\n",
    "      camera_projections: A dict of {laser_name,\n",
    "        [camera_projection_from_first_return,\n",
    "        camera_projection_from_second_return]}.\n",
    "      seg_labels: segmentation labels, a dict of {laser_name,\n",
    "        [seg_label_first_return, seg_label_second_return]}\n",
    "      range_image_top_pose: range image pixel pose for top lidar.\n",
    "    \"\"\"\n",
    "    range_images = {}\n",
    "    camera_projections = {}\n",
    "    seg_labels = {}\n",
    "    range_image_top_pose: dataset_pb2.MatrixFloat = dataset_pb2.MatrixFloat()\n",
    "    for laser in frame.lasers:\n",
    "        if len(laser.ri_return1.range_image_compressed) > 0:  # pylint: disable=g-explicit-length-test\n",
    "            range_image_str_tensor = tf.io.decode_compressed(laser.ri_return1.range_image_compressed, \"ZLIB\")\n",
    "            ri = dataset_pb2.MatrixFloat()\n",
    "            ri.ParseFromString(range_image_str_tensor.numpy())\n",
    "            range_images[laser.name] = [ri]\n",
    "\n",
    "            if laser.name == dataset_pb2.LaserName.TOP:\n",
    "                range_image_top_pose_str_tensor = tf.io.decode_compressed(\n",
    "                    laser.ri_return1.range_image_pose_compressed, \"ZLIB\"\n",
    "                )\n",
    "                range_image_top_pose = dataset_pb2.MatrixFloat()\n",
    "                range_image_top_pose.ParseFromString(range_image_top_pose_str_tensor.numpy())\n",
    "\n",
    "            camera_projection_str_tensor = tf.io.decode_compressed(\n",
    "                laser.ri_return1.camera_projection_compressed, \"ZLIB\"\n",
    "            )\n",
    "            cp = dataset_pb2.MatrixInt32()\n",
    "            cp.ParseFromString(camera_projection_str_tensor.numpy())\n",
    "            camera_projections[laser.name] = [cp]\n",
    "\n",
    "            if len(laser.ri_return1.segmentation_label_compressed) > 0:  # pylint: disable=g-explicit-length-test\n",
    "                seg_label_str_tensor = tf.io.decode_compressed(laser.ri_return1.segmentation_label_compressed, \"ZLIB\")\n",
    "                seg_label = dataset_pb2.MatrixInt32()\n",
    "                seg_label.ParseFromString(seg_label_str_tensor.numpy())\n",
    "                seg_labels[laser.name] = [seg_label]\n",
    "        if len(laser.ri_return2.range_image_compressed) > 0:  # pylint: disable=g-explicit-length-test\n",
    "            range_image_str_tensor = tf.io.decode_compressed(laser.ri_return2.range_image_compressed, \"ZLIB\")\n",
    "            ri = dataset_pb2.MatrixFloat()\n",
    "            ri.ParseFromString(range_image_str_tensor.numpy())\n",
    "            range_images[laser.name].append(ri)\n",
    "\n",
    "            camera_projection_str_tensor = tf.io.decode_compressed(\n",
    "                laser.ri_return2.camera_projection_compressed, \"ZLIB\"\n",
    "            )\n",
    "            cp = dataset_pb2.MatrixInt32()\n",
    "            cp.ParseFromString(camera_projection_str_tensor.numpy())\n",
    "            camera_projections[laser.name].append(cp)\n",
    "\n",
    "            if len(laser.ri_return2.segmentation_label_compressed) > 0:  # pylint: disable=g-explicit-length-test\n",
    "                seg_label_str_tensor = tf.io.decode_compressed(laser.ri_return2.segmentation_label_compressed, \"ZLIB\")\n",
    "                seg_label = dataset_pb2.MatrixInt32()\n",
    "                seg_label.ParseFromString(seg_label_str_tensor.numpy())\n",
    "                seg_labels[laser.name].append(seg_label)\n",
    "    return range_images, camera_projections, seg_labels, range_image_top_pose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from waymo_open_dataset.utils import frame_utils\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(tfrecords_file_list[file_idx], compression_type=\"\")\n",
    "for data in dataset:\n",
    "    frame = dataset_pb2.Frame()\n",
    "    frame.ParseFromString(data.numpy())  # No need for bytearray conversion\n",
    "    break\n",
    "\n",
    "(range_images, camera_projections, _, range_image_top_pose) = parse_range_image_and_camera_projection(frame)\n",
    "points, cp_points = frame_utils.convert_range_image_to_point_cloud(\n",
    "    frame=frame,\n",
    "    range_images=range_images,\n",
    "    camera_projections=camera_projections,\n",
    "    range_image_top_pose=range_image_top_pose,\n",
    "    keep_polar_features=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = points[0]\n",
    "\n",
    "\n",
    "plt.scatter(pc[:, 3], pc[:, 4], s=0.1, c=pc[:, 5], cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_points[0].shape, points[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d123",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
