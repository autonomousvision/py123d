{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from waymo_open_dataset import dataset_pb2\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from waymo_open_dataset import label_pb2\n",
    "from waymo_open_dataset.protos import camera_segmentation_pb2 as cs_pb2\n",
    "from waymo_open_dataset.utils import box_utils\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "WOPD_DATA_ROOT = Path(\"/media/nvme1/waymo_perception/training\")\n",
    "\n",
    "\n",
    "tfrecords_file_list = list(WOPD_DATA_ROOT.glob(\"*.tfrecord\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from pyquaternion import Quaternion\n",
    "\n",
    "from d123.geometry import StateSE3\n",
    "from d123.geometry.bounding_box import BoundingBoxSE3\n",
    "\n",
    "from waymo_open_dataset.utils import frame_utils\n",
    "\n",
    "\n",
    "# Frame attributes:\n",
    "#   context: <class 'waymo_open_dataset.dataset_pb2.Context'>\n",
    "#   timestamp_micros: <class 'int'>\n",
    "#   pose: <class 'waymo_open_dataset.dataset_pb2.Transform'>\n",
    "#   images: List with 5 images\n",
    "#   lasers: <class 'google._upb._message.RepeatedCompositeContainer'>\n",
    "#     Length: 5\n",
    "#   laser_labels: <class 'google._upb._message.RepeatedCompositeContainer'>\n",
    "#     Length: 0\n",
    "#   projected_lidar_labels: <class 'google._upb._message.RepeatedCompositeContainer'>\n",
    "#     Length: 0\n",
    "#   camera_labels: <class 'google._upb._message.RepeatedCompositeContainer'>\n",
    "#     Length: 0\n",
    "#   no_label_zones: <class 'google._upb._message.RepeatedCompositeContainer'>\n",
    "#     Length: 0\n",
    "#   map_features: <class 'google._upb._message.RepeatedCompositeContainer'>\n",
    "#     Length: 0\n",
    "#   map_pose_offset: <class 'waymo_open_dataset.protos.vector_pb2.Vector3d'>\n",
    "\n",
    "file_idx = 0\n",
    "pathname = tfrecords_file_list[file_idx]\n",
    "dataset = tf.data.TFRecordDataset(pathname, compression_type=\"\")\n",
    "num_frames = sum(1 for _ in dataset)\n",
    "\n",
    "\n",
    "def read_jpg_image(data: bytes) -> np.ndarray:\n",
    "    \"\"\"Read a JPEG image from bytes and return it as a numpy array.\"\"\"\n",
    "    image = Image.open(io.BytesIO(data))\n",
    "    return np.array(image)\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(pathname, compression_type=\"\")\n",
    "\n",
    "\n",
    "for frame_idx, data in enumerate(dataset):\n",
    "\n",
    "    frame = dataset_pb2.Frame()\n",
    "    frame.ParseFromString(data.numpy())\n",
    "    print(frame.context)\n",
    "\n",
    "    # # plt.show()\n",
    "    if frame_idx == 0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for laser_calibration in frame.context.laser_calibrations:\n",
    "    print(np.array(laser_calibration.extrinsic.transform).reshape(4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame_idx, data in enumerate(dataset):\n",
    "    frame = dataset_pb2.Frame()\n",
    "    frame.ParseFromString(data.numpy())\n",
    "    if frame_idx == 2:\n",
    "        break\n",
    "\n",
    "print(\"Ego\")\n",
    "ego_transform = np.array(frame.pose.transform).reshape(4, 4)\n",
    "print(ego_transform[:3, 3])\n",
    "\n",
    "# 1 [ 1.5441613  -0.02302364  2.11557864]\n",
    "# 2 [1.49672397 0.0954948  2.11616463]\n",
    "# 3 [ 1.49442485 -0.09637497  2.11519385]\n",
    "# 4 [1.43213651 0.11612398 2.11625087]\n",
    "# 5 [ 1.42936162 -0.11545043  2.1150792 ]\n",
    "\n",
    "\n",
    "# frame.map_pose_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(64, 20))\n",
    "\n",
    "\n",
    "def plot_range_image_helper(data, name, layout, vmin=0, vmax=1, cmap=\"gray\"):\n",
    "    \"\"\"Plots range image.\n",
    "\n",
    "    Args:\n",
    "      data: range image data\n",
    "      name: the image title\n",
    "      layout: plt layout\n",
    "      vmin: minimum value of the passed data\n",
    "      vmax: maximum value of the passed data\n",
    "      cmap: color map\n",
    "    \"\"\"\n",
    "    plt.subplot(*layout)\n",
    "    plt.imshow(data, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    plt.title(name)\n",
    "    plt.grid(False)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "def get_range_image(laser_name, return_index):\n",
    "    \"\"\"Returns range image given a laser name and its return index.\"\"\"\n",
    "    return range_images[laser_name][return_index]\n",
    "\n",
    "\n",
    "# def show_range_image(range_image, layout_index_start=1):\n",
    "#     \"\"\"Shows range image.\n",
    "\n",
    "#     Args:\n",
    "#       range_image: the range image data from a given lidar of type MatrixFloat.\n",
    "#       layout_index_start: layout offset\n",
    "#     \"\"\"\n",
    "#     range_image_tensor = tf.convert_to_tensor(range_image.data)\n",
    "#     range_image_tensor = tf.reshape(range_image_tensor, range_image.shape.dims)\n",
    "#     lidar_image_mask = tf.greater_equal(range_image_tensor, 0)\n",
    "#     range_image_tensor = tf.where(lidar_image_mask, range_image_tensor, tf.ones_like(range_image_tensor) * 1e10)\n",
    "#     range_image_range = range_image_tensor[..., 0]\n",
    "#     range_image_intensity = range_image_tensor[..., 1]\n",
    "#     range_image_elongation = range_image_tensor[..., 2]\n",
    "#     plot_range_image_helper(range_image_range.numpy(), \"range\", [8, 1, layout_index_start], vmax=75, cmap=\"gray\")\n",
    "#     plot_range_image_helper(\n",
    "#         range_image_intensity.numpy(), \"intensity\", [8, 1, layout_index_start + 1], vmax=1.5, cmap=\"gray\"\n",
    "#     )\n",
    "#     plot_range_image_helper(\n",
    "#         range_image_elongation.numpy(), \"elongation\", [8, 1, layout_index_start + 2], vmax=1.5, cmap=\"gray\"\n",
    "#     )\n",
    "\n",
    "\n",
    "def show_range_image(range_image, layout_index_start=1):\n",
    "    \"\"\"Shows range image.\n",
    "\n",
    "    Args:\n",
    "      range_image: the range image data from a given lidar of type MatrixFloat.\n",
    "      layout_index_start: layout offset\n",
    "    \"\"\"\n",
    "    range_image_tensor = np.array([data for data in range_image.data]).reshape(range_image.shape.dims)\n",
    "    lidar_image_mask = np.greater_equal(range_image_tensor, 0)\n",
    "    range_image_tensor = np.where(lidar_image_mask, range_image_tensor, np.ones_like(range_image_tensor) * 1e10)\n",
    "    range_image_range = range_image_tensor[..., 0]\n",
    "    range_image_intensity = range_image_tensor[..., 1]\n",
    "    range_image_elongation = range_image_tensor[..., 2]\n",
    "    plot_range_image_helper(range_image_range, \"range\", [8, 1, layout_index_start], vmax=75, cmap=\"gray\")\n",
    "    plot_range_image_helper(range_image_intensity, \"intensity\", [8, 1, layout_index_start + 1], vmax=1.5, cmap=\"gray\")\n",
    "    plot_range_image_helper(range_image_elongation, \"elongation\", [8, 1, layout_index_start + 2], vmax=1.5, cmap=\"gray\")\n",
    "\n",
    "\n",
    "frame.lasers.sort(key=lambda laser: laser.name)\n",
    "show_range_image(get_range_image(open_dataset.LaserName.TOP, 0), 1)\n",
    "# show_range_image(get_range_image(open_dataset.LaserName.TOP, 1), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from d123.common.datatypes.time.time_point import TimePoint\n",
    "\n",
    "\n",
    "for frame_idx, data in enumerate(dataset):\n",
    "    frame = dataset_pb2.Frame()\n",
    "    frame.ParseFromString(data.numpy())\n",
    "    if frame_idx == 4:\n",
    "        break\n",
    "    break\n",
    "\n",
    "\n",
    "# for calibration in frame.context.camera_calibrations:\n",
    "\n",
    "frame.timestamp_micros, frame.images[0].pose_timestamp\n",
    "# frame.images[0]\n",
    "\n",
    "frame_timestamp = TimePoint.from_us(frame.timestamp_micros)\n",
    "image_timestamp = TimePoint.from_s(frame.images[0].pose_timestamp)\n",
    "frame_timestamp.time_s, frame_timestamp.time_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d123",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
