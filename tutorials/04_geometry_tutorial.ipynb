{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"left\">\n",
    "  <picture>\n",
    "    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://autonomousvision.github.io/py123d/_static/123D_logo_transparent_white.svg\" width=\"500\">\n",
    "    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://autonomousvision.github.io/py123d/_static/123D_logo_transparent_black.svg\" width=\"500\">\n",
    "    <img alt=\"Logo\" src=\"https://autonomousvision.github.io/py123d/_static/123D_logo_transparent_black.svg\" width=\"500\">\n",
    "  </picture>\n",
    "  <h2 align=\"left\">123D: Geometry Tutorial</h1>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from py123d.geometry import (\n",
    "    BoundingBoxSE2,\n",
    "    BoundingBoxSE3,\n",
    "    EulerAngles,\n",
    "    Point2D,\n",
    "    Point3D,\n",
    "    Polyline2D,\n",
    "    Polyline3D,\n",
    "    PolylineSE2,\n",
    "    PoseSE2,\n",
    "    PoseSE3,\n",
    "    Quaternion,\n",
    "    Vector2D,\n",
    "    Vector3D,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Introduction\n",
    "\n",
    "The `py123d.geometry` module provides geometric primitives for working with autonomous driving data. All classes share a common design:\n",
    "\n",
    "- **Array-backed**: Each object wraps a NumPy array, accessible via the `.array` property.\n",
    "- **Immutable**: Objects cannot be modified after creation.\n",
    "- **Index enums**: Named indices (e.g., `Point3DIndex.X`) provide readable array access.\n",
    "- **Interoperable**: Objects can be constructed from arrays (`from_array`) and converted to NumPy arrays (`np.array(obj)`).\n",
    "\n",
    "This tutorial requires **no dataset downloads** -- all examples are self-contained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Points and Vectors\n",
    "\n",
    "Points represent locations in space, while vectors represent displacements. The key difference is how they interact:\n",
    "- `Point - Point = Vector` (displacement between two locations)\n",
    "- `Point + Vector = Point` (translate a location)\n",
    "- `Vector + Vector = Vector` (combine displacements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 `Point2D` and `Point3D`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create points directly\n",
    "p2d = Point2D(1.0, 2.0)\n",
    "print(\"Point2D:\\t\", p2d)\n",
    "print(\"x, y:\\t\\t\", p2d.x, p2d.y)\n",
    "print(\"Array:\\t\\t\", p2d.array)\n",
    "\n",
    "p3d = Point3D(1.0, 2.0, 3.0)\n",
    "print(\"\\nPoint3D:\\t\", p3d)\n",
    "print(\"x, y, z:\\t\", p3d.x, p3d.y, p3d.z)\n",
    "\n",
    "# Create from arrays\n",
    "p2d_from_array = Point2D.from_array(np.array([5.0, 6.0]))\n",
    "print(\"\\nFrom array:\\t\", p2d_from_array)\n",
    "\n",
    "# 3D to 2D projection\n",
    "print(\"3D -> 2D:\\t\", p3d.point_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 `Vector2D` and `Vector3D`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = Vector2D(3.0, 4.0)\n",
    "v2 = Vector2D(1.0, 0.0)\n",
    "\n",
    "print(\"v1:\\t\\t\", v1)\n",
    "print(\"v1.magnitude:\\t\", v1.magnitude)\n",
    "\n",
    "# Arithmetic operations\n",
    "print(\"\\nv1 + v2:\\t\", v1 + v2)\n",
    "print(\"v1 - v2:\\t\", v1 - v2)\n",
    "print(\"v1 * 2:\\t\\t\", v1 * 2)\n",
    "print(\"v1 / 2:\\t\\t\", v1 / 2)\n",
    "print(\"-v1:\\t\\t\", -v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Point-Vector Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Point2D(1.0, 1.0)\n",
    "v = Vector2D(2.0, 3.0)\n",
    "\n",
    "# Translate a point by a vector\n",
    "p_translated = p + v\n",
    "print(\"Point + Vector:\\t\", p_translated, f\"(type: {type(p_translated).__name__})\")\n",
    "\n",
    "# Displacement between two points\n",
    "p2 = Point2D(4.0, 5.0)\n",
    "displacement = p2 - p\n",
    "print(\"Point - Point:\\t\", displacement, f\"(type: {type(displacement).__name__})\")\n",
    "\n",
    "# Move a point backward\n",
    "p_back = p - v\n",
    "print(\"Point - Vector:\\t\", p_back, f\"(type: {type(p_back).__name__})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize point-vector arithmetic\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# Points\n",
    "ax.plot(p.x, p.y, \"ko\", markersize=8, label=\"p = (1, 1)\")\n",
    "ax.plot(p_translated.x, p_translated.y, \"bs\", markersize=8, label=f\"p + v = ({p_translated.x}, {p_translated.y})\")\n",
    "ax.plot(p2.x, p2.y, \"r^\", markersize=8, label=f\"p2 = ({p2.x}, {p2.y})\")\n",
    "\n",
    "# Vectors as arrows\n",
    "ax.annotate(\n",
    "    \"\", xy=(p_translated.x, p_translated.y), xytext=(p.x, p.y), arrowprops=dict(arrowstyle=\"->\", color=\"blue\", lw=2)\n",
    ")\n",
    "ax.text(2.0, 2.8, f\"v = ({v.x}, {v.y})\", color=\"blue\", fontsize=10)\n",
    "\n",
    "ax.annotate(\"\", xy=(p2.x, p2.y), xytext=(p.x, p.y), arrowprops=dict(arrowstyle=\"->\", color=\"red\", lw=2))\n",
    "ax.text(2.8, 2.5, f\"p2 - p = ({displacement.x}, {displacement.y})\", color=\"red\", fontsize=10)\n",
    "\n",
    "ax.set_xlim(-0.5, 6)\n",
    "ax.set_ylim(-0.5, 6)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "ax.set_title(\"Point-Vector Arithmetic\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Rotations\n",
    "Rotations in 123D have three different representations, that you might encounter:\n",
    "\n",
    "| Representation | Parameters | \\#Params | Notes |\n",
    "|---|---|---|---|\n",
    "| **Euler angles** | roll, pitch, yaw | 3 | Intuitive but subject to gimbal lock. Rotation order is intrinsic Z-Y'-X'' (yaw-pitch-roll). |\n",
    "| **Quaternions** | qw, qx, qy, qz | 4 | Compact, no gimbal lock, used internally with scale-first convention in `PoseSE3`. |\n",
    "| **Rotation matrices** | 3×3 matrix | 9 | Useful for matrix operations. 9 parameters but only 3 DOF due to orthonormality constraints. |\n",
    "\n",
    "All three representations are mathematically equivalent, but **quaternions are the default representation in 123D**. \n",
    "Please be cautious with Euler angles due to gimbal lock and rotation-order conventions. \n",
    "\n",
    "Note that `PosseSE2` internally simply uses yaw angles in radian, but provides a 2×2 rotation matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 `EulerAngles`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Euler angles: 90-degree yaw rotation (turn left)\n",
    "euler = EulerAngles(roll=0.0, pitch=0.0, yaw=np.pi / 2)\n",
    "print(\"EulerAngles:\\t\", euler)\n",
    "print(\"roll:\\t\\t\", euler.roll)\n",
    "print(\"pitch:\\t\\t\", euler.pitch)\n",
    "print(\"yaw:\\t\\t\", euler.yaw)\n",
    "\n",
    "# Convert to rotation matrix\n",
    "print(\"\\nRotation matrix:\")\n",
    "print(euler.rotation_matrix.round(4))\n",
    "\n",
    "# Convert to quaternion\n",
    "print(\"\\nQuaternion:\\t\", euler.quaternion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 `Quaternion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity quaternion (no rotation)\n",
    "q_identity = Quaternion(qw=1.0, qx=0.0, qy=0.0, qz=0.0)\n",
    "print(\"Identity quaternion:\\t\", q_identity)\n",
    "print(\"Rotation matrix:\")\n",
    "print(q_identity.rotation_matrix)\n",
    "\n",
    "# Create from rotation matrix\n",
    "R_90 = np.array([[0, -1, 0], [1, 0, 0], [0, 0, 1]], dtype=np.float64)  # 90-degree yaw\n",
    "q_from_R = Quaternion.from_rotation_matrix(R_90)\n",
    "print(\"\\nFrom rotation matrix:\", q_from_R)\n",
    "print(\"Euler angles:\\t\\t\", q_from_R.euler_angles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 Conversion Roundtrip\n",
    "\n",
    "All rotation representations are consistent -- converting between them preserves the rotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with Euler angles\n",
    "euler_original = EulerAngles(roll=0.1, pitch=0.2, yaw=0.3)\n",
    "\n",
    "# Euler -> Quaternion -> Rotation Matrix -> Euler\n",
    "quat = euler_original.quaternion\n",
    "rot_matrix = quat.rotation_matrix\n",
    "euler_roundtrip = EulerAngles.from_rotation_matrix(rot_matrix)\n",
    "\n",
    "print(\"Original:\\t\", euler_original)\n",
    "print(\"Roundtrip:\\t\", euler_roundtrip)\n",
    "print(\"Match:\\t\\t\", np.allclose(euler_original.array, euler_roundtrip.array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Poses\n",
    "\n",
    "Poses combine translation and rotation into a single rigid-body transformation:\n",
    "- `PoseSE2`: 2D pose with (x, y, yaw)\n",
    "- `PoseSE3`: 3D pose with (x, y, z, qw, qx, qy, qz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 `PoseSE2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2D pose\n",
    "pose_2d = PoseSE2(x=5.0, y=3.0, yaw=np.pi / 4)  # 45-degree rotation\n",
    "print(\"PoseSE2:\\t\", pose_2d)\n",
    "print(\"Point:\\t\\t\", pose_2d.point_2d)\n",
    "print(\"Yaw (deg):\\t\", np.degrees(pose_2d.yaw))\n",
    "\n",
    "# 2x2 rotation matrix\n",
    "print(\"\\nRotation matrix:\")\n",
    "print(pose_2d.rotation_matrix.round(4))\n",
    "\n",
    "# 3x3 transformation matrix\n",
    "print(\"\\nTransformation matrix:\")\n",
    "print(pose_2d.transformation_matrix.round(4))\n",
    "\n",
    "# Identity pose\n",
    "print(\"\\nIdentity:\\t\", PoseSE2.identity())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 `PoseSE3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3D pose with identity rotation\n",
    "pose_3d = PoseSE3(x=10.0, y=20.0, z=1.0, qw=1.0, qx=0.0, qy=0.0, qz=0.0)\n",
    "print(\"PoseSE3:\\t\", pose_3d)\n",
    "print(\"Point3D:\\t\", pose_3d.point_3d)\n",
    "print(\"Point2D:\\t\", pose_3d.point_2d)\n",
    "print(\"Quaternion:\\t\", pose_3d.quaternion)\n",
    "print(\"Euler angles:\\t\", pose_3d.euler_angles)\n",
    "\n",
    "# Create from rotation + translation\n",
    "euler = EulerAngles(roll=0.0, pitch=0.0, yaw=np.pi / 2)\n",
    "translation = Point3D(5.0, 10.0, 0.0)\n",
    "pose_from_R_t = PoseSE3.from_R_t(rotation=euler, translation=translation)\n",
    "print(\"\\nFrom R, t:\\t\", pose_from_R_t)\n",
    "print(\"Yaw (deg):\\t\", np.degrees(pose_from_R_t.yaw))\n",
    "\n",
    "# SE3 -> SE2 projection\n",
    "print(\"\\nSE3 -> SE2:\\t\", pose_from_R_t.pose_se2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3 Construction Methods\n",
    "\n",
    "`PoseSE3` supports flexible construction from various rotation and translation types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From rotation matrix + numpy array\n",
    "R = np.eye(3, dtype=np.float64)\n",
    "t = np.array([1.0, 2.0, 3.0])\n",
    "p1 = PoseSE3.from_R_t(rotation=R, translation=t)\n",
    "\n",
    "# From Quaternion + Vector3D\n",
    "q = Quaternion(1.0, 0.0, 0.0, 0.0)\n",
    "v = Vector3D(1.0, 2.0, 3.0)\n",
    "p2 = PoseSE3.from_R_t(rotation=q, translation=v)\n",
    "\n",
    "# From 4x4 transformation matrix\n",
    "T = np.eye(4, dtype=np.float64)\n",
    "T[:3, 3] = [1.0, 2.0, 3.0]\n",
    "p3 = PoseSE3.from_transformation_matrix(T)\n",
    "\n",
    "print(\"From R, t (arrays):\\t\", p1)\n",
    "print(\"From Q, V (typed):\\t\", p2)\n",
    "print(\"From 4x4 matrix:\\t\", p3)\n",
    "print(\"All equal:\\t\\t\", p1 == p2 == p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.4 Transformation Matrix Roundtrip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = PoseSE3.from_R_t(\n",
    "    rotation=EulerAngles(roll=0.1, pitch=0.2, yaw=0.3),\n",
    "    translation=Point3D(10.0, 20.0, 5.0),\n",
    ")\n",
    "\n",
    "# Pose -> Transformation matrix -> Pose\n",
    "T = pose.transformation_matrix\n",
    "pose_roundtrip = PoseSE3.from_transformation_matrix(T)\n",
    "\n",
    "print(\"Original:\\t\", pose)\n",
    "print(\"Roundtrip:\\t\", pose_roundtrip)\n",
    "print(\"Match:\\t\\t\", np.allclose(pose.array, pose_roundtrip.array))\n",
    "\n",
    "print(\"\\n4x4 Transformation matrix:\")\n",
    "print(T.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Index Enums\n",
    "\n",
    "All geometry classes use `IntEnum`-based index enums for readable array access. This makes code self-documenting when working with raw arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py123d.geometry import (\n",
    "    Corners3DIndex,\n",
    "    MatrixSE3Index,\n",
    "    PoseSE3Index,\n",
    ")\n",
    "\n",
    "# Individual element access\n",
    "pose_array = pose.array\n",
    "print(\"x:\\t\", pose_array[PoseSE3Index.X])\n",
    "print(\"y:\\t\", pose_array[PoseSE3Index.Y])\n",
    "print(\"z:\\t\", pose_array[PoseSE3Index.Z])\n",
    "print(\"qw:\\t\", pose_array[PoseSE3Index.QW])\n",
    "\n",
    "# Slice access (via classproperty)\n",
    "print(\"\\nXYZ:\\t\", pose_array[PoseSE3Index.XYZ])\n",
    "print(\"QUAT:\\t\", pose_array[PoseSE3Index.QUATERNION])\n",
    "\n",
    "# Matrix indexing\n",
    "T = pose.transformation_matrix\n",
    "print(\"\\nRotation block (3x3):\")\n",
    "print(T[MatrixSE3Index.ROTATION].round(4))\n",
    "print(\"\\nTranslation (3,):\\t\", T[MatrixSE3Index.TRANSLATION])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Bounding Boxes\n",
    "\n",
    "Bounding boxes are defined by a center pose and extents (length, width, and optionally height). They are used for object detection annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.1 `BoundingBoxSE2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a rotated 2D bounding box\n",
    "center = PoseSE2(x=5.0, y=3.0, yaw=np.pi / 6)  # 30-degree rotation\n",
    "bbox_2d = BoundingBoxSE2(center_se2=center, length=4.0, width=2.0)\n",
    "\n",
    "print(\"BoundingBoxSE2:\\t\", bbox_2d)\n",
    "print(\"Center:\\t\\t\", bbox_2d.center_se2)\n",
    "print(\"Length:\\t\\t\", bbox_2d.length)\n",
    "print(\"Width:\\t\\t\", bbox_2d.width)\n",
    "print(\"Area:\\t\\t\", bbox_2d.shapely_polygon.area)\n",
    "\n",
    "# Get corners\n",
    "corners = bbox_2d.corners_array\n",
    "print(\"\\nCorners (4x2):\")\n",
    "print(corners.round(4))\n",
    "\n",
    "# Named corner access\n",
    "corners_dict = bbox_2d.corners_dict\n",
    "for name, corner in corners_dict.items():\n",
    "    print(f\"  {name.name}:\\t{corner}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize multiple bounding boxes at different orientations\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "cmap = plt.get_cmap(\"tab10\")\n",
    "yaw_degrees = np.arange(0, 180, 30)\n",
    "colors = cmap(np.linspace(0, 1, len(yaw_degrees)))\n",
    "x_offsets = np.linspace(-5, 5, len(yaw_degrees))\n",
    "for i, (yaw_deg, x_offset) in enumerate(zip(yaw_degrees, x_offsets)):\n",
    "    yaw_rad = np.radians(yaw_deg)\n",
    "    bbox = BoundingBoxSE2(\n",
    "        center_se2=PoseSE2(x=x_offset, y=0.0, yaw=yaw_rad),\n",
    "        length=4.0,\n",
    "        width=2.0,\n",
    "    )\n",
    "    corners = bbox.corners_array\n",
    "    closed = np.vstack([corners, corners[0]])\n",
    "    ax.fill(closed[:, 0], closed[:, 1], alpha=0.3, color=colors[i])\n",
    "    ax.plot(closed[:, 0], closed[:, 1], color=colors[i], label=f\"yaw={yaw_deg}°\")\n",
    "\n",
    "    dx = 2.0 * np.cos(yaw_rad)\n",
    "    dy = 2.0 * np.sin(yaw_rad)\n",
    "    ax.annotate(\n",
    "        \"\",\n",
    "        xy=(x_offset + dx, dy),\n",
    "        xytext=(x_offset, 0),\n",
    "        arrowprops=dict(arrowstyle=\"->\", color=colors[i], lw=1.5),\n",
    "    )\n",
    "\n",
    "ax.set_xlim(-8, 8)\n",
    "ax.set_ylim(-4, 4)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_title(\"BoundingBoxSE2 at different yaw angles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.2 `BoundingBoxSE3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3D bounding box\n",
    "center_3d = PoseSE3(x=10.0, y=5.0, z=1.0, qw=1.0, qx=0.0, qy=0.0, qz=0.0)\n",
    "bbox_3d = BoundingBoxSE3(center_se3=center_3d, length=4.5, width=2.0, height=1.8)\n",
    "\n",
    "print(\"BoundingBoxSE3:\\t\", bbox_3d)\n",
    "print(\"Length:\\t\\t\", bbox_3d.length)\n",
    "print(\"Width:\\t\\t\", bbox_3d.width)\n",
    "print(\"Height:\\t\\t\", bbox_3d.height)\n",
    "\n",
    "# 8 corners of the 3D box\n",
    "corners_3d = bbox_3d.corners_array\n",
    "print(\"\\nCorners (8x3):\")\n",
    "print(corners_3d.round(4))\n",
    "\n",
    "# Named corner access\n",
    "corners_3d_dict = bbox_3d.corners_dict\n",
    "for name, corner in corners_3d_dict.items():\n",
    "    print(f\"  {name.name}:\\t{corner}\")\n",
    "\n",
    "# SE3 -> SE2 projection\n",
    "print(\"\\nSE2 projection:\\t\", bbox_3d.bounding_box_se2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the 3D bounding box\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "# Get the 8 corners of the box\n",
    "corners = bbox_3d.corners_array\n",
    "\n",
    "# Define the 12 edges of the box by connecting corner indices\n",
    "edges = [\n",
    "    (Corners3DIndex.FRONT_LEFT_BOTTOM, Corners3DIndex.FRONT_RIGHT_BOTTOM),\n",
    "    (Corners3DIndex.FRONT_RIGHT_BOTTOM, Corners3DIndex.BACK_RIGHT_BOTTOM),\n",
    "    (Corners3DIndex.BACK_RIGHT_BOTTOM, Corners3DIndex.BACK_LEFT_BOTTOM),\n",
    "    (Corners3DIndex.BACK_LEFT_BOTTOM, Corners3DIndex.FRONT_LEFT_BOTTOM),\n",
    "    (Corners3DIndex.FRONT_LEFT_TOP, Corners3DIndex.FRONT_RIGHT_TOP),\n",
    "    (Corners3DIndex.FRONT_RIGHT_TOP, Corners3DIndex.BACK_RIGHT_TOP),\n",
    "    (Corners3DIndex.BACK_RIGHT_TOP, Corners3DIndex.BACK_LEFT_TOP),\n",
    "    (Corners3DIndex.BACK_LEFT_TOP, Corners3DIndex.FRONT_LEFT_TOP),\n",
    "    (Corners3DIndex.FRONT_LEFT_BOTTOM, Corners3DIndex.FRONT_LEFT_TOP),\n",
    "    (Corners3DIndex.FRONT_RIGHT_BOTTOM, Corners3DIndex.FRONT_RIGHT_TOP),\n",
    "    (Corners3DIndex.BACK_RIGHT_BOTTOM, Corners3DIndex.BACK_RIGHT_TOP),\n",
    "    (Corners3DIndex.BACK_LEFT_BOTTOM, Corners3DIndex.BACK_LEFT_TOP),\n",
    "]\n",
    "\n",
    "# Plot the edges\n",
    "for start, end in edges:\n",
    "    ax.plot(corners[[start, end], 0], corners[[start, end], 1], corners[[start, end], 2], \"b-\")\n",
    "\n",
    "# Plot the corners and their labels\n",
    "for corner_idx in Corners3DIndex:\n",
    "    x, y, z = corners[corner_idx]\n",
    "    ax.scatter(x, y, z, c=\"r\", marker=\"o\")\n",
    "    ax.text(x, y, z, f\"  {corner_idx.name}\", color=\"purple\", fontsize=8)\n",
    "\n",
    "\n",
    "# Plot the center\n",
    "center = bbox_3d.center_se3\n",
    "ax.scatter(center.x, center.y, center.z, c=\"g\", marker=\"^\", s=100)\n",
    "ax.text(center.x, center.y, center.z, \"  Center\", color=\"green\", fontsize=8)\n",
    "\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "ax.set_title(\"BoundingBoxSE3 Visualization\")\n",
    "\n",
    "# Set aspect ratio to be equal\n",
    "ax.set_box_aspect([np.ptp(corners[:, i]) for i in range(3)])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Polylines\n",
    "\n",
    "Polylines represent sequences of connected points. They support interpolation, projection, and length computation. Three variants are available:\n",
    "- `Polyline2D`: 2D path (x, y)\n",
    "- `Polyline3D`: 3D path (x, y, z)\n",
    "- `PolylineSE2`: 2D path with heading (x, y, yaw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7.1 `Polyline2D`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a polyline from a numpy array\n",
    "points = np.array(\n",
    "    [\n",
    "        [0.0, 0.0],\n",
    "        [2.0, 1.0],\n",
    "        [4.0, 0.5],\n",
    "        [6.0, 2.0],\n",
    "        [8.0, 1.0],\n",
    "    ]\n",
    ")\n",
    "polyline = Polyline2D.from_array(points)\n",
    "\n",
    "print(\"Length:\\t\\t\", round(polyline.length, 4))\n",
    "print(\"Array shape:\\t\", polyline.array.shape)\n",
    "\n",
    "# Interpolate at a specific distance\n",
    "mid_point = polyline.interpolate(polyline.length / 2)\n",
    "print(\"\\nMidpoint:\\t\", mid_point)\n",
    "\n",
    "# Interpolate with normalized distance (0 to 1)\n",
    "quarter_point = polyline.interpolate(0.25, normalized=True)\n",
    "print(\"Quarter point:\\t\", quarter_point)\n",
    "\n",
    "# Project a point onto the polyline\n",
    "query_point = Point2D(4.0, 2.0)\n",
    "distance_along = polyline.project(query_point)\n",
    "print(f\"\\nProjection of {query_point}:\\t{round(float(distance_along), 4)} meters along polyline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize polyline interpolation\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Draw the polyline\n",
    "ax.plot(polyline.array[:, 0], polyline.array[:, 1], \"b-o\", linewidth=2, label=\"Polyline\")\n",
    "\n",
    "# Mark interpolated points along the polyline\n",
    "n_samples = 20\n",
    "distances = np.linspace(0.01, polyline.length - 0.01, n_samples)\n",
    "interp_points = polyline.interpolate(distances)\n",
    "ax.scatter(interp_points[:, 0], interp_points[:, 1], c=distances, cmap=\"viridis\", s=60, zorder=5, label=\"Interpolated\")\n",
    "plt.colorbar(ax.collections[-1], ax=ax, label=\"Distance along polyline [m]\")\n",
    "\n",
    "# Mark the projected point\n",
    "closest = polyline.interpolate(float(distance_along))\n",
    "ax.plot(query_point.x, query_point.y, \"r*\", markersize=15, label=\"Query point\")\n",
    "ax.plot(closest.x, closest.y, \"g*\", markersize=15, label=\"Closest on polyline\")\n",
    "ax.plot([query_point.x, closest.x], [query_point.y, closest.y], \"r--\", alpha=0.5)\n",
    "\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "ax.set_title(\"Polyline2D: Interpolation and Projection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7.2 `PolylineSE2`\n",
    "\n",
    "`PolylineSE2` extends `Polyline2D` with heading information. It can be created from SE2 states or from a `Polyline2D` (where headings are inferred from the path direction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create from SE2 array (x, y, yaw)\n",
    "# Create a smooth, curvy path using a sine wave\n",
    "num_points = 30\n",
    "x = np.linspace(0, 4 * np.pi, num_points)\n",
    "y = 2 * np.sin(x / 2)\n",
    "\n",
    "# Calculate yaw as the angle of the path's tangent\n",
    "yaw = np.arctan2(np.gradient(y), np.gradient(x))\n",
    "\n",
    "# Create the SE2 states array (x, y, yaw)\n",
    "se2_states = np.stack([x, y, yaw], axis=-1)\n",
    "\n",
    "polyline_se2 = PolylineSE2.from_array(se2_states)\n",
    "\n",
    "# or from 2d points:\n",
    "polyline_se2 = PolylineSE2.from_array(se2_states[..., PoseSE3Index.XY])\n",
    "\n",
    "\n",
    "print(\"Length:\\t\\t\", round(polyline_se2.length, 4))\n",
    "\n",
    "# Interpolation returns PoseSE2 (with heading)\n",
    "interp_pose = polyline_se2.interpolate(polyline_se2.length / 2)\n",
    "print(\"Midpoint pose:\\t\", interp_pose)\n",
    "print(\"Midpoint yaw:\\t\", round(np.degrees(interp_pose.yaw), 2), \"degrees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PolylineSE2 with heading arrows\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Draw the path\n",
    "ax.plot(se2_states[:, 0], se2_states[:, 1], \"b-o\", linewidth=2, label=\"Path\")\n",
    "\n",
    "# Draw heading arrows at each waypoint\n",
    "arrow_len = 0.5\n",
    "for state in se2_states:\n",
    "    x, y, yaw = state\n",
    "    dx = arrow_len * np.cos(yaw)\n",
    "    dy = arrow_len * np.sin(yaw)\n",
    "    ax.annotate(\"\", xy=(x + dx, y + dy), xytext=(x, y), arrowprops=dict(arrowstyle=\"->\", color=\"red\", lw=2))\n",
    "\n",
    "# Sample interpolated poses along the path\n",
    "n_samples = 15\n",
    "distances = np.linspace(0.01, polyline_se2.length - 0.01, n_samples)\n",
    "for d in distances:\n",
    "    pose = polyline_se2.interpolate(float(d))\n",
    "    ax.plot(pose.x, pose.y, \"g.\", markersize=6)\n",
    "    dx = 0.3 * np.cos(pose.yaw)\n",
    "    dy = 0.3 * np.sin(pose.yaw)\n",
    "    ax.annotate(\n",
    "        \"\",\n",
    "        xy=(pose.x + dx, pose.y + dy),\n",
    "        xytext=(pose.x, pose.y),\n",
    "        arrowprops=dict(arrowstyle=\"->\", color=\"green\", lw=1, alpha=0.7),\n",
    "    )\n",
    "\n",
    "ax.plot([], [], \"r->\", label=\"Waypoint heading\")\n",
    "ax.plot([], [], \"g->\", label=\"Interpolated heading\")\n",
    "\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "ax.set_title(\"PolylineSE2: Path with Heading\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7.3 `Polyline3D`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3D polyline\n",
    "points_3d = np.array(\n",
    "    [\n",
    "        [0.0, 0.0, 0.0],\n",
    "        [1.0, 1.0, 1.0],\n",
    "        [2.0, 0.0, 2.0],\n",
    "        [3.0, 1.0, 1.5],\n",
    "    ]\n",
    ")\n",
    "polyline_3d = Polyline3D.from_array(points_3d)\n",
    "\n",
    "print(\"Length:\\t\\t\", round(polyline_3d.length, 4))\n",
    "\n",
    "# Interpolate along the 3D path\n",
    "mid_3d = polyline_3d.interpolate(polyline_3d.length / 2)\n",
    "print(\"Midpoint:\\t\", mid_3d)\n",
    "\n",
    "# Convert to 2D polyline\n",
    "polyline_2d = polyline_3d.polyline_2d\n",
    "print(\"\\n2D projection length:\", round(polyline_2d.length, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 Coordinate Transforms\n",
    "\n",
    "The `py123d.geometry.transform` module provides functions to convert poses and points between coordinate frames. This is essential in autonomous driving where data is represented in different frames (e.g., global, ego vehicle, sensor).\n",
    "\n",
    "Three main operations are available:\n",
    "- `abs_to_rel`: Convert from absolute (global) to relative (local) coordinates\n",
    "- `rel_to_abs`: Convert from relative (local) to absolute (global) coordinates\n",
    "- `reframe`: Convert directly between two reference frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8.1 Absolute <-> Relative (SE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py123d.geometry.transform import (\n",
    "    abs_to_rel_point_2d,\n",
    "    abs_to_rel_se2,\n",
    "    rel_to_abs_point_2d,\n",
    "    rel_to_abs_se2,\n",
    ")\n",
    "\n",
    "# Define an origin (e.g., ego vehicle at position (3, 2) facing 90 degrees)\n",
    "origin_se2 = PoseSE2(x=3.0, y=2.0, yaw=np.pi / 2)\n",
    "\n",
    "# A point in absolute coordinates\n",
    "abs_point_2d = Point2D(x=5.0, y=4.0)\n",
    "abs_pose_se2 = PoseSE2(x=5.0, y=4.0, yaw=np.pi / 4)\n",
    "# Transform the point from absolute to relative coordinates (relative to the ego vehicle)\n",
    "rel_point_2d = abs_to_rel_point_2d(origin_se2, abs_point_2d)\n",
    "print(f\"Absolute point:\\t\\t{abs_point_2d}\")\n",
    "print(f\"Relative to ego:\\t{rel_point_2d}\")\n",
    "\n",
    "# Transform back to absolute coordinates to verify\n",
    "abs_point_recovered = rel_to_abs_point_2d(origin_se2, rel_point_2d)\n",
    "print(f\"Back to absolute:\\t{abs_point_recovered}\")\n",
    "print(f\"Match:\\t\\t\\t{np.allclose(abs_point_2d.array, abs_point_recovered.array)}\")\n",
    "\n",
    "# Do the same for a PoseSE2\n",
    "rel_pose = abs_to_rel_se2(origin_se2, abs_pose_se2)\n",
    "print(f\"\\nAbsolute pose:\\t\\t{abs_pose_se2}\")\n",
    "print(f\"Relative to ego:\\t{rel_pose}\")\n",
    "\n",
    "# Convert back to absolute\n",
    "abs_pose_recovered = rel_to_abs_se2(origin_se2, rel_pose)\n",
    "print(f\"Back to absolute:\\t{abs_pose_recovered}\")\n",
    "print(f\"Match:\\t\\t\\t{np.allclose(abs_pose_se2.array, abs_pose_recovered.array)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize coordinate transformation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Left: Absolute frame\n",
    "ax = axes[0]\n",
    "ax.set_title(\"Absolute (Global) Frame\")\n",
    "\n",
    "# Draw origin (ego vehicle)\n",
    "ax.plot(origin_se2.x, origin_se2.y, \"rs\", markersize=12, label=\"Ego vehicle\")\n",
    "arrow_len = 1.5\n",
    "ax.annotate(\n",
    "    \"\",\n",
    "    xy=(origin_se2.x + arrow_len * np.cos(origin_se2.yaw), origin_se2.y + arrow_len * np.sin(origin_se2.yaw)),\n",
    "    xytext=(origin_se2.x, origin_se2.y),\n",
    "    arrowprops=dict(arrowstyle=\"->\", color=\"red\", lw=2),\n",
    ")\n",
    "\n",
    "# Draw some objects in absolute coordinates\n",
    "objects_abs = [Point2D(5.0, 4.0), Point2D(1.0, 4.0), Point2D(4.0, 0.0)]\n",
    "for i, obj in enumerate(objects_abs):\n",
    "    ax.plot(obj.x, obj.y, \"bo\", markersize=10)\n",
    "    ax.annotate(f\"  Obj {i}\", (obj.x, obj.y), fontsize=10)\n",
    "\n",
    "ax.set_xlim(-1, 7)\n",
    "ax.set_ylim(-2, 6)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlabel(\"Global X\")\n",
    "ax.set_ylabel(\"Global Y\")\n",
    "ax.legend()\n",
    "\n",
    "# Right: Relative (ego) frame\n",
    "ax = axes[1]\n",
    "ax.set_title(\"Relative (Ego) Frame\")\n",
    "\n",
    "# Ego is at origin in its own frame\n",
    "ax.plot(0, 0, \"rs\", markersize=12, label=\"Ego vehicle\")\n",
    "ax.annotate(\"\", xy=(arrow_len, 0), xytext=(0, 0), arrowprops=dict(arrowstyle=\"->\", color=\"red\", lw=2))\n",
    "\n",
    "# Transform objects to ego frame\n",
    "for i, obj in enumerate(objects_abs):\n",
    "    rel_obj = abs_to_rel_point_2d(origin_se2, obj)\n",
    "    ax.plot(rel_obj.x, rel_obj.y, \"bo\", markersize=10)\n",
    "    ax.annotate(f\"  Obj {i}\", (rel_obj.x, rel_obj.y), fontsize=10)\n",
    "\n",
    "ax.set_xlim(-5, 5)\n",
    "ax.set_ylim(-5, 5)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlabel(\"Ego X (forward)\")\n",
    "ax.set_ylabel(\"Ego Y (left)\")\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8.2 Absolute <-> Relative (SE3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py123d.geometry.transform import abs_to_rel_point_3d, abs_to_rel_se3, rel_to_abs_point_3d, rel_to_abs_se3\n",
    "\n",
    "# Define a 3D origin\n",
    "origin_3d = PoseSE3.from_R_t(\n",
    "    rotation=EulerAngles(roll=0.0, pitch=0.0, yaw=np.pi / 4),\n",
    "    translation=Point3D(10.0, 5.0, 1.0),\n",
    ")\n",
    "\n",
    "# A 3D point in absolute coordinates\n",
    "abs_point_3d = Point3D(12.0, 7.0, 2.0)\n",
    "\n",
    "# Transform to relative coordinates\n",
    "rel_point_3d = abs_to_rel_point_3d(origin_3d, abs_point_3d)\n",
    "print(f\"Absolute:\\t{abs_point_3d}\")\n",
    "print(f\"Relative:\\t{rel_point_3d}\")\n",
    "\n",
    "# Transform back\n",
    "recovered = rel_to_abs_point_3d(origin_3d, rel_point_3d)\n",
    "print(f\"Recovered:\\t{recovered}\")\n",
    "print(f\"Match:\\t\\t{np.allclose(abs_point_3d.array, recovered.array)}\")\n",
    "\n",
    "# SE3 pose transformation\n",
    "abs_pose_se2 = PoseSE3.from_R_t(\n",
    "    rotation=EulerAngles(roll=0.0, pitch=0.0, yaw=np.pi),\n",
    "    translation=Point3D(15.0, 10.0, 2.0),\n",
    ")\n",
    "rel_pose = abs_to_rel_se3(origin_3d, abs_pose_se2)\n",
    "recovered_pose = rel_to_abs_se3(origin_3d, rel_pose)\n",
    "print(f\"\\nPose roundtrip match: {np.allclose(abs_pose_se2.array, recovered_pose.array)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8.3 Reframing Between Frames\n",
    "\n",
    "`reframe` converts directly between two reference frames without going through absolute coordinates explicitly. This is useful when transforming data from one sensor's frame to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py123d.geometry.transform import reframe_point_2d, reframe_se2\n",
    "\n",
    "# Two reference frames (e.g., two different timesteps of the ego vehicle)\n",
    "frame_t0 = PoseSE2(x=0.0, y=0.0, yaw=0.0)  # t=0: at origin, facing forward\n",
    "frame_t1 = PoseSE2(x=5.0, y=2.0, yaw=np.pi / 2)  # t=1: moved and rotated\n",
    "\n",
    "# A point known in frame_t0\n",
    "point_in_t0 = Point2D(x=3.0, y=1.0)\n",
    "pose_in_t0 = PoseSE2(x=3.0, y=1.0, yaw=0.0)\n",
    "\n",
    "\n",
    "# Convert to frame_t1\n",
    "point_in_t1 = reframe_point_2d(from_origin=frame_t0, to_origin=frame_t1, point_2d=point_in_t0)\n",
    "pose_in_t1 = reframe_se2(from_origin=frame_t0, to_origin=frame_t1, pose_se2=pose_in_t0)\n",
    "\n",
    "print(f\"Point in t0 frame:\\t{point_in_t0}\")\n",
    "print(f\"Point in t1 frame:\\t{point_in_t1}\")\n",
    "print(f\"Pose in t1 frame:\\t{pose_in_t1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8.4 Body-Frame Translations\n",
    "\n",
    "Translate a pose along its own coordinate axes (e.g., move a vehicle forward or sideways):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py123d.geometry.transform import translate_se2_along_body_frame, translate_se2_along_x, translate_se2_along_y\n",
    "\n",
    "# A pose facing 45 degrees\n",
    "pose = PoseSE2(x=0.0, y=0.0, yaw=np.pi / 4)\n",
    "\n",
    "# Translate along the body's forward (x) direction\n",
    "forward = translate_se2_along_x(pose, distance=3.0)\n",
    "print(f\"Original:\\t{pose}\")\n",
    "print(f\"Forward 3m:\\t{forward}\")\n",
    "\n",
    "# Translate along the body's left (y) direction\n",
    "left = translate_se2_along_y(pose, distance=2.0)\n",
    "print(f\"Left 2m:\\t{left}\")\n",
    "\n",
    "# Arbitrary body-frame translation\n",
    "custom = translate_se2_along_body_frame(pose, Vector2D(3.0, 2.0))\n",
    "print(f\"Custom (3,2):\\t{custom}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize body-frame translations\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "\n",
    "def draw_pose(ax, pose, color, label, arrow_len=1.0):\n",
    "    ax.plot(pose.x, pose.y, \"o\", color=color, markersize=10)\n",
    "    dx = arrow_len * np.cos(pose.yaw)\n",
    "    dy = arrow_len * np.sin(pose.yaw)\n",
    "    ax.annotate(\n",
    "        \"\",\n",
    "        xy=(pose.x + dx, pose.y + dy),\n",
    "        xytext=(pose.x, pose.y),\n",
    "        arrowprops=dict(arrowstyle=\"->\", color=color, lw=2),\n",
    "    )\n",
    "    ax.annotate(f\"  {label}\", (pose.x, pose.y), fontsize=10, color=color)\n",
    "\n",
    "\n",
    "draw_pose(ax, pose, \"black\", \"Original\")\n",
    "draw_pose(ax, forward, \"blue\", \"Forward 3m\")\n",
    "draw_pose(ax, left, \"green\", \"Left 2m\")\n",
    "draw_pose(ax, custom, \"red\", \"Custom (3, 2)\")\n",
    "\n",
    "# Draw body axes at the original pose\n",
    "body_x_end = (2.0 * np.cos(pose.yaw), 2.0 * np.sin(pose.yaw))\n",
    "body_y_end = (2.0 * np.cos(pose.yaw + np.pi / 2), 2.0 * np.sin(pose.yaw + np.pi / 2))\n",
    "ax.annotate(\"\", xy=body_x_end, xytext=(0, 0), arrowprops=dict(arrowstyle=\"->\", color=\"grey\", lw=1, linestyle=\"--\"))\n",
    "ax.annotate(\"\", xy=body_y_end, xytext=(0, 0), arrowprops=dict(arrowstyle=\"->\", color=\"grey\", lw=1, linestyle=\"--\"))\n",
    "ax.text(body_x_end[0] + 0.1, body_x_end[1] + 0.1, \"body x\", color=\"grey\", fontsize=9)\n",
    "ax.text(body_y_end[0] + 0.1, body_y_end[1] + 0.1, \"body y\", color=\"grey\", fontsize=9)\n",
    "\n",
    "ax.set_xlim(-3, 5)\n",
    "ax.set_ylim(-2, 5)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_title(\"Body-Frame Translations\")\n",
    "ax.set_xlabel(\"Global X\")\n",
    "ax.set_ylabel(\"Global Y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8.5 Batch Transforms\n",
    "\n",
    "Array functions (suffixed with `_array`) operate on batches of poses or points for efficient vectorized computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py123d.geometry import PoseSE2Index\n",
    "from py123d.geometry.transform import abs_to_rel_points_2d_array, abs_to_rel_se2_array\n",
    "\n",
    "# Ego vehicle origin\n",
    "origin_se2 = PoseSE2(x=5.0, y=5.0, yaw=np.pi / 4)\n",
    "\n",
    "# Batch of 100 random points in absolute coordinates\n",
    "np.random.seed(42)\n",
    "abs_points = np.random.uniform(0, 10, size=(100, 2))\n",
    "\n",
    "# Batch transform to relative coordinates\n",
    "rel_points = abs_to_rel_points_2d_array(origin_se2, abs_points)\n",
    "\n",
    "print(f\"Input shape:\\t{abs_points.shape}\")\n",
    "print(f\"Output shape:\\t{rel_points.shape}\")\n",
    "\n",
    "# Batch SE2 transform\n",
    "abs_poses = np.random.uniform(0, 10, size=(50, 3))  # 50 random poses\n",
    "abs_poses[:, PoseSE2Index.YAW] = np.random.uniform(-np.pi, np.pi, size=50)\n",
    "rel_poses = abs_to_rel_se2_array(origin_se2, abs_poses)\n",
    "print(f\"\\nSE2 batch: {abs_poses.shape} -> {rel_poses.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize batch transform\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "for ax, pts, title, xlabel, ylabel in [\n",
    "    (axes[0], abs_points, \"Absolute Frame\", \"Global X\", \"Global Y\"),\n",
    "    (axes[1], rel_points, \"Relative (Ego) Frame\", \"Ego X (forward)\", \"Ego Y (left)\"),\n",
    "]:\n",
    "    ax.scatter(pts[:, 0], pts[:, 1], s=15, alpha=0.6, c=\"steelblue\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Draw ego in both frames\n",
    "for ax, x, y, yaw in [(axes[0], origin_se2.x, origin_se2.y, origin_se2.yaw), (axes[1], 0, 0, 0)]:\n",
    "    ax.plot(x, y, \"rs\", markersize=12, label=\"Ego\")\n",
    "    ax.annotate(\n",
    "        \"\",\n",
    "        xy=(x + 2 * np.cos(yaw), y + 2 * np.sin(yaw)),\n",
    "        xytext=(x, y),\n",
    "        arrowprops=dict(arrowstyle=\"->\", color=\"red\", lw=2),\n",
    "    )\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.9 NumPy Interoperability\n",
    "\n",
    "All geometry objects implement `__array__`, so they work directly with NumPy functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = Point3D(1.0, 2.0, 3.0)\n",
    "\n",
    "# Direct conversion to numpy array\n",
    "arr = np.array(point)\n",
    "print(\"np.array(point):\\t\", arr)\n",
    "print(\"dtype:\\t\\t\\t\", arr.dtype)\n",
    "\n",
    "# With dtype casting\n",
    "arr_f32 = np.array(point, dtype=np.float32)\n",
    "print(\"as float32:\\t\\t\", arr_f32)\n",
    "\n",
    "# Indexing and slicing\n",
    "print(\"\\npoint[0]:\\t\\t\", point[0])\n",
    "print(\"point[:2]:\\t\\t\", point[:2])\n",
    "print(\"len(point):\\t\\t\", len(point))\n",
    "print(\"point.shape:\\t\\t\", point.shape)\n",
    "print(\"point.tolist():\\t\\t\", point.tolist())\n",
    "\n",
    "# Equality comparison\n",
    "p1 = Point3D(1.0, 2.0, 3.0)\n",
    "p2 = Point3D(1.0, 2.0, 3.0)\n",
    "p3 = Point3D(4.0, 5.0, 6.0)\n",
    "print(\"\\np1 == p2:\\t\\t\", p1 == p2)\n",
    "print(\"p1 == p3:\\t\\t\", p1 == p3)\n",
    "\n",
    "list_of_points = [Point3D(1.0, 2.0, 3.0), Point3D(4.0, 5.0, 6.0)]\n",
    "print(\"\\nList of points:\\t\\t\", list_of_points)\n",
    "array_of_points = np.array(list_of_points)\n",
    "print(\"Array of points:\\t\", array_of_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.10 Performance: Think in Arrays, Not Objects\n",
    "\n",
    "The typed geometry classes (`Point3D`, `PoseSE3`, `Vector3D`, etc.) are designed for **readability, type safety, and single-element access**. They are ideal for writing clear, self-documenting code when working with individual values.\n",
    "\n",
    "However, when processing **batches of data** (e.g., transforming a Lidar point cloud or a trajectory of poses), you should always operate on raw NumPy arrays using the `_array`-suffixed functions. The performance difference is dramatic because:\n",
    "\n",
    "1. **No Python-level object creation** -- each `Point3D(...)` or `PoseSE3(...)` involves Python overhead.\n",
    "2. **Vectorized math** -- NumPy dispatches the entire batch to optimized C/BLAS routines in a single call.\n",
    "3. **Cache-friendly memory access** -- contiguous arrays are processed efficiently by the CPU.\n",
    "\n",
    "Let's measure the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "from py123d.geometry.transform import abs_to_rel_point_3d, abs_to_rel_points_3d_array\n",
    "\n",
    "# A reference frame (e.g., ego vehicle pose)\n",
    "origin = PoseSE3.from_R_t(\n",
    "    rotation=EulerAngles(roll=0.1, pitch=0.2, yaw=0.3),\n",
    "    translation=Point3D(10.0, 20.0, 5.0),\n",
    ")\n",
    "\n",
    "# Generate a batch of 10,000 random 3D points (e.g., a Lidar point cloud)\n",
    "np.random.seed(0)\n",
    "N = 10_000\n",
    "points_batch = np.random.uniform(-50, 50, size=(N, 3))\n",
    "\n",
    "\n",
    "# --- Approach 1: Python for-loop with typed objects ---\n",
    "def transform_loop():\n",
    "    return np.array([abs_to_rel_point_3d(origin, Point3D(*p)).array for p in points_batch])\n",
    "\n",
    "\n",
    "# --- Approach 2: Vectorized batch transform ---\n",
    "def transform_batch():\n",
    "    return abs_to_rel_points_3d_array(origin, points_batch)\n",
    "\n",
    "\n",
    "# Verify both produce the same result\n",
    "result_loop = transform_loop()\n",
    "result_batch = transform_batch()\n",
    "print(f\"Results match: {np.allclose(result_loop, result_batch)}\")\n",
    "\n",
    "# Benchmark\n",
    "n_repeats = 5\n",
    "t_loop = timeit.timeit(transform_loop, number=n_repeats) / n_repeats\n",
    "t_batch = timeit.timeit(transform_batch, number=n_repeats) / n_repeats\n",
    "\n",
    "print(f\"\\nTransforming {N:,} points from absolute to relative coordinates:\")\n",
    "print(f\"  For-loop (typed objects): {t_loop * 1000:.2f} ms\")\n",
    "print(f\"  Batch (NumPy array):      {t_batch * 1000:.2f} ms\")\n",
    "print(f\"  Speedup:                  {t_loop / t_batch:.0f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the gap scale with batch size?\n",
    "batch_sizes = [10, 100, 1_000, 10_000, 100_000]\n",
    "times_loop = []\n",
    "times_batch = []\n",
    "\n",
    "for n in batch_sizes:\n",
    "    pts = np.random.uniform(-50, 50, size=(n, 3))\n",
    "\n",
    "    # What not to do:\n",
    "    def _loop(pts=pts):\n",
    "        return np.array([abs_to_rel_point_3d(origin, Point3D(*p)).array for p in pts])\n",
    "\n",
    "    # What to do:\n",
    "    def _batch(pts=pts):\n",
    "        return abs_to_rel_points_3d_array(origin, pts)\n",
    "\n",
    "    repeats = max(1, 200_000 // n)  # fewer repeats for large batches\n",
    "    times_loop.append(timeit.timeit(_loop, number=repeats) / repeats * 1000)\n",
    "    times_batch.append(timeit.timeit(_batch, number=repeats) / repeats * 1000)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.loglog(batch_sizes, times_loop, \"o-\", label=\"For-loop (typed objects)\", color=\"tab:red\")\n",
    "ax.loglog(batch_sizes, times_batch, \"s-\", label=\"Batch (NumPy array)\", color=\"tab:blue\")\n",
    "ax.set_xlabel(\"Number of points\")\n",
    "ax.set_ylabel(\"Time [ms]\")\n",
    "ax.set_title(\"SE3 Point Transform: For-Loop vs. Batch\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, which=\"both\")\n",
    "\n",
    "# Annotate speedup\n",
    "for n, tl, tb in zip(batch_sizes, times_loop, times_batch):\n",
    "    ax.annotate(\n",
    "        f\"{tl / tb:.0f}x\",\n",
    "        xy=(n, tb),\n",
    "        xytext=(0, -18),\n",
    "        textcoords=\"offset points\",\n",
    "        fontsize=9,\n",
    "        ha=\"center\",\n",
    "        color=\"tab:blue\",\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, 123D uses NumPy for simplicity. Because all batch operations are expressed as array computations (matrix multiplications, broadcasting, einsum), the same logic could be extended to PyTorch or JAX in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You made it to the end. For further information, visit the [documentation](https://autonomousvision.github.io/py123d/) or check out the other tutorials for working with scenes, maps, and visualizations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py123d_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
