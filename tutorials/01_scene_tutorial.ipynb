{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "<h1 align=\"left\">\n",
    "  <picture>\n",
    "    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://autonomousvision.github.io/py123d/_static/123D_logo_transparent_white.svg\" width=\"500\">\n",
    "    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://autonomousvision.github.io/py123d/_static/123D_logo_transparent_black.svg\" width=\"500\">\n",
    "    <img alt=\"Logo\" src=\"https://autonomousvision.github.io/py123d/_static/123D_logo_transparent_black.svg\" width=\"500\">\n",
    "  </picture>\n",
    "  <h2 align=\"left\">123D: Scene Tutorial</h1>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from py123d.api import SceneAPI, SceneFilter\n",
    "from py123d.api.scene.arrow.arrow_scene_builder import ArrowSceneBuilder\n",
    "from py123d.common.multithreading.worker_parallel import SingleMachineParallelExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1.1 Download Demo Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 1.2 Create Scenes by filtering the datasets\n",
    "\n",
    "\n",
    "\n",
    "The logs store continuous driving recordings. Scenes in 123D are sequences that are extracted from a log, e.g. given a predefined duration and history.\n",
    "\n",
    "In the example below, we filter some scenes from all logs with 8 second duration and 8 seconds temporal distance (making the scenes non-overlapping). If `None` is passed to the duration, the scene will contain the complete log.\n",
    "\n",
    "This `SceneFilter` object is passed to a `SceneBuilder` object to query `SceneAPI`'s from the dataset.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py123d.datatypes.sensors import PinholeCamera, PinholeCameraType\n",
    "\n",
    "scene_filter = SceneFilter(\n",
    "    split_names=None,\n",
    "    log_names=None,\n",
    "    scene_uuids=None,\n",
    "    duration_s=7.0,\n",
    "    history_s=0.0,\n",
    "    timestamp_threshold_s=7.0,\n",
    "    pinhole_camera_types=[PinholeCameraType.PCAM_F0],\n",
    "    shuffle=True,\n",
    ")\n",
    "scene_builder = ArrowSceneBuilder()\n",
    "worker = SingleMachineParallelExecutor()\n",
    "\n",
    "# worker = RayDistributed()\n",
    "scenes = scene_builder.get_scenes(scene_filter, worker)\n",
    "print(f\"Found {len(scenes)} scenes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasplits = []\n",
    "\n",
    "for scene in scenes:\n",
    "    datasplits.append(scene.log_metadata.split)\n",
    "\n",
    "\n",
    "print(set(datasplits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 1.2 Inspecting the Scene\n",
    "\n",
    "Let's inspect a random scenefrom our dataset.\n",
    "\n",
    "A scene has several different metadata objects attached to it:\n",
    "\n",
    "`SceneMetadata`: Information how the scene was extracted from the log. Each timestep in the log has universally unique identifier (UUID). The UUID of the initial timestep also serves as identifier for scene filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene: SceneAPI = np.random.choice(scenes)\n",
    "scene_metadata = scene.scene_metadata\n",
    "print(scene_metadata)\n",
    "print(\"\\nInitial UUID:\", scene_metadata.initial_uuid)\n",
    "print(\"Number of iterations:\", scene_metadata.number_of_iterations)\n",
    "print(\"Number of history iterations:\", scene_metadata.number_of_history_iterations)\n",
    "print(\"Duration (s):\", scene_metadata.duration_s)\n",
    "print(\"Iteration duration (s):\", scene_metadata.iteration_duration_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "`LogMetadata`: Information of the log the scene was extracted from. This object also includes data about the map (if available), or static information of the ego vehicle, e.g. the included sensors and vehicle parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_metadata = scene.log_metadata\n",
    "log_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "`MapMetadata`: If the map is available, this object includes information about the location, wether the map is 3D (`map_has_z`), of the the map is defined per log (`map_is_local`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_metadata = scene.map_metadata\n",
    "map_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 1.3 Retrieving data from the `SceneAPI`\n",
    "\n",
    "Different datasets might provide different modalities. In general, you can load data using a `scene.get_modality_at_iteration(iteration=...)`\n",
    "\n",
    "If a modality is not available, the return will be `None`. The `TimePoint` is the only modality that is strictly required to be available in a `Scene\n",
    "\n",
    "Let's look at some examples:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### 1.3.1 `TimePoint`\n",
    "\n",
    "Current time step in microseconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py123d.datatypes.time import TimePoint\n",
    "\n",
    "iteration = 0\n",
    "timepoint: TimePoint = scene.get_timepoint_at_iteration(iteration=iteration)\n",
    "print(f\"Time at iteration {iteration}:\", timepoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### 1.3.2 `EgoStateSE3` \n",
    "State of the ego vehicle in 3D with location and orientation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py123d.datatypes.vehicle_state import EgoStateSE3\n",
    "\n",
    "if (ego_state := scene.get_ego_state_at_iteration(iteration=iteration)) is not None:\n",
    "    ego_state: EgoStateSE3\n",
    "\n",
    "    print(\"Vehicle parameters\\t\", ego_state.vehicle_parameters)\n",
    "\n",
    "    # The ego vehicles coordinate system is defined by it's rear-axle / IMU location.\n",
    "    print(\"Rear axle location:\\t\", ego_state.rear_axle_se3.point_3d)\n",
    "    print(\"Rear axle orientation:\\t\", ego_state.rear_axle_se3.quaternion)\n",
    "\n",
    "    # You can also use the center pose\n",
    "    print(\"Center location:\\t\", ego_state.center_se3.point_3d)\n",
    "    print(\"Center orientation:\\t\", ego_state.center_se3.quaternion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### 1.3.3 `BoxDetectionWrapper`\n",
    "\n",
    "Object that contains all bounding boxes in the current time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py123d.datatypes.detections import BoxDetectionWrapper\n",
    "\n",
    "if (box_detections := scene.get_box_detections_at_iteration(iteration=iteration)) is not None:\n",
    "    box_detections: BoxDetectionWrapper\n",
    "\n",
    "    print(f\"Number of boxes:{len(box_detections)}\")\n",
    "\n",
    "    if len(box_detections) > 0:\n",
    "        box_detection = box_detections[0]\n",
    "        print(\"\\nFirst box:\")\n",
    "        print(\"Dataset Label:\\t\", box_detection.metadata.label)\n",
    "        print(\"Default Label:\\t\", box_detection.metadata.default_label)\n",
    "        print(\"Parameters:\\t\", box_detection.bounding_box_se3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### 1.3.4 `PinholeCamera`\n",
    "Object containing the camera observation with a pinhole model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_pinhole_types = scene.available_pinhole_camera_types\n",
    "print(\"Available pinhole camera types:\\t\", available_pinhole_types)\n",
    "\n",
    "if len(available_pinhole_types) > 0:\n",
    "    camera_type = np.random.choice(available_pinhole_types)\n",
    "else:\n",
    "    camera_type = PinholeCameraType.PCAM_F0  # Front facing camera\n",
    "\n",
    "# NOTE: If a camera is not available, the return will be None\n",
    "if (pinhole_camera := scene.get_pinhole_camera_at_iteration(iteration=iteration, camera_type=camera_type)) is not None:\n",
    "    pinhole_camera: PinholeCamera\n",
    "\n",
    "    print(f\"\\nCamera type:\\t{camera_type}\")\n",
    "\n",
    "    print(f\"Image shape:\\t{pinhole_camera.image.shape}\")\n",
    "    print(f\"Intrinsics:\\t{pinhole_camera.metadata.intrinsics}\")\n",
    "    print(f\"Distortion:\\t{pinhole_camera.metadata.distortion}\")\n",
    "\n",
    "    plt.imshow(pinhole_camera.image)\n",
    "    plt.title(f\"Camera Type: {camera_type}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### 1.3.5 `LiDAR`\n",
    "Object containing a point cloud of a single laser scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py123d.datatypes.sensors import LiDAR, LiDARType\n",
    "\n",
    "available_lidar_types = scene.available_lidar_types\n",
    "print(\"Available LiDAR types:\\t\", available_lidar_types)\n",
    "\n",
    "if len(available_lidar_types) > 0:\n",
    "    lidar_type = np.random.choice(available_lidar_types)\n",
    "else:\n",
    "    lidar_type = LiDARType.LIDAR_TOP  # Top mounted LiDAR\n",
    "\n",
    "if (lidar := scene.get_lidar_at_iteration(iteration=iteration, lidar_type=lidar_type)) is not None:\n",
    "    lidar: LiDAR\n",
    "\n",
    "    print(f\"\\nLiDAR type:\\t{lidar_type}\")\n",
    "    print(f\"Shape (NxM):\\t{lidar.point_cloud.shape}\")\n",
    "    print(f\"Features (M):\\t{[(enum.name, enum.value) for enum in lidar.metadata.lidar_index]}\")\n",
    "\n",
    "    xy = lidar.xy\n",
    "\n",
    "    plt.scatter(xy[:, 0], xy[:, 1], s=0.1, alpha=0.25, c=\"black\")\n",
    "    plt.title(f\"LiDAR Type: {lidar_type}\")\n",
    "    plt.xlabel(\"X-forward [m]\")\n",
    "    plt.ylabel(\"Y-left [m]\")\n",
    "    plt.axis(\"equal\")\n",
    "\n",
    "    range_limit = 100  # meters\n",
    "    plt.xlim(-range_limit, range_limit)\n",
    "    plt.ylim(-range_limit, range_limit)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### 1.3.6 `MapAPI`\n",
    "\n",
    "The `MapAPI` can get retrieved from a scene directly. If the map is available, we plot the map with our default plotting function.\n",
    "For further information, you can visit the map or visualization tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py123d.api import MapAPI\n",
    "from py123d.geometry import Point2D\n",
    "from py123d.visualization.matplotlib.observation import add_default_map_on_ax\n",
    "from py123d.visualization.matplotlib.utils import add_non_repeating_legend_to_ax\n",
    "\n",
    "\n",
    "def simple_map_visualization(map_api: MapAPI, center_2d: Point2D, map_radius: float = 100.0):\n",
    "    \"\"\"Helper to plot the map using matplotlib.\n",
    "\n",
    "    :param map_api: The MapAPI to visualize\n",
    "    :param center_2d: The center point of the map visualization\n",
    "    :param map_radius: The radius around the center point to visualize\n",
    "    \"\"\"\n",
    "\n",
    "    fsize = 8\n",
    "    _, ax = plt.subplots(figsize=(fsize, fsize))\n",
    "    add_default_map_on_ax(ax, map_api=map_api, point_2d=center_2d, radius=map_radius)\n",
    "    add_non_repeating_legend_to_ax(ax)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xlim(center_2d.x - map_radius, center_2d.x + map_radius)\n",
    "    ax.set_ylim(center_2d.y - map_radius, center_2d.y + map_radius)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if (map_api := scene.get_map_api()) is not None:\n",
    "    map_api: MapAPI\n",
    "\n",
    "    if (ego_state := scene.get_ego_state_at_iteration(iteration=iteration)) is not None:\n",
    "        center_2d = ego_state.center_se3.point_2d\n",
    "    else:\n",
    "        center_2d = Point2D.from_array(np.array([0.0, 0.0]))\n",
    "\n",
    "    print(\"\\nMapAPI is available.\")\n",
    "    print(\"Map Metadata:\", map_api.map_metadata)\n",
    "    simple_map_visualization(map_api=map_api, center_2d=center_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### 1.3.7 Others:\n",
    "\n",
    "You can find further modalities in the documentation of [`SceneAPI`](todo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py123d_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
